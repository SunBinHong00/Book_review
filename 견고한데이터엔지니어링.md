# 1장 데이터 엔지니어링 상세

## 1.1 데이터 엔지니어링이란?

- **데이터 엔지니어링**:
  - 다른 전문가가 데이터를 사용할 수 있도록 만드는 일련의 작업.
  - 대규모 데이터 수집 및 저장.
  - 추가 분석을 수행할 수 있는 데이터를 준비하기 위한 시스템 설계 및 구축.

### SQL 중심

- 데이터 작업 및 기본 저장소는 RDS.
- 때때로 이러한 처리는 ETL 도구를 사용해 수행.

### 빅데이터 중심

- 데이터 작업 및 기본 스토리지:
  - 하둡, 카산드라, 스파크, 플링크.
- SQL이 사용되는 동안 기본 처리는 프로그래밍 언어로 이루어진다.

### 1.1.1 데이터 엔지니어링 정의

- **데이터 엔지니어링**:
  - Raw data를 가져와 분석 및 머신러닝 등 다운스트림 사용 사례를 지원.
  - 고품질의 일관된 정보를 생성하는 시스템과 프로세스 개발, 구현 및 유지 관리.
  - 보안, 데이터 관리, 데이터 운영, 데이터 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링.

### 1.1.2 데이터 엔지니어링 수명 주기

- **데이터 엔지니어링 수명 주기**:
  - 생성
  - 저장
  - 수집
  - 변환
  - 서빙

### 1.1.4 데이터 엔지니어링과 데이터 과학

- **학습/최적화**: AI, 딥러닝
- **집계/라벨링**: A/B 테스트, 실험, 단순 ML 알고리즘
- **탐색/변환**: 정제, 이상 감지, 준비
- **이동/저장**: 데이터 흐름, 인프라, 파이프라인, ETL, 정형/비정형 데이터 저장
- **수집**: 계측, 로깅, 센서, 외부 데이터, 사용자 생성 콘텐츠

**원천 시스템으로부터의 데이터 > 데이터 엔지니어링 > 데이터 과학과 분석**

## 1.2 데이터 엔지니어링 기술과 활동

- **데이터 엔지니어의 기술역량**:
  - 보안
  - 데이터 관리
  - 데이터옵스
  - 데이터 아키텍처 및 소프트웨어 엔지니어링
  - 최적화:
    - 비용
    - 민첩성
    - 확장성
    - 단순성
    - 재사용성
    - 상호 운용성

### 1.2.1 데이터 성숙도와 데이터 엔지니어

- **데이터 성숙도**:
  - 데이터 활용률, 기능, 통합
  - 데이터 관리 성숙도(DMM)

- **단순화된 기업용 데이터 성숙도 모델**:
  1. 데이터로 시작하기
  2. 데이터로 확장하기
  3. 데이터로 선도하기

#### 1단계: 데이터로 시작하기

- 이 단계에서 데이터 엔지니어는 보통 제너럴리스트.
- 데이터 엔지니어의 목표는 빠르게 움직이고, 견인력을 얻고, 부가가치를 창출.
- 데이터로부터 가치를 창출하는 일에 수요가 존재.
- 이 단계에서 ML에 먼저 뛰어들고 싶지만 권장하지 않음.

- **데이터 조직의 중점 사항**:
  - 경영진을 포함한 주요 관계자의 지원 확보.
  - 적절한 데이터 아키텍처 정의 및 구축.
  - 주요 이니셔티브를 지원하면서 데이터 검수.
  - 데이터 기반을 구축하여 보고서 및 모델 생성.

- **팁**:
  - 데이터로 가시적인 성공을 만들어 조직 의지를 유지.
  - 외부와 소통하며 관계자 피드백 수렴.
  - 과중한 업무 방지 및 불필요한 기술 복잡성 회피.
  - 경쟁 우위를 제공할 때만 맞춤형 솔루션 구축.

#### 2단계: 데이터로 확장하기

이번 과제는 확장성 있는 데이터 아키텍처를 구축하고, 기업이 진정으로 데이터 중심인 미래를 계획하는 것.

- **데이터 성숙도 2단계**:
  - 공식적인 데이터 관행 수립.
  - 확장성 있고 견고한 데이터 아키텍처 구축.
  - DevOps 및 DataOps 관행 채택.
  - ML을 지원하는 시스템 구축.
  - 차별화되지 않은 과중한 업무를 피하고 경쟁 우위를 확보할 때만 커스터마이징.

- **주의깊게 살펴볼 문제**:
  - 최신 기술을 무조건 추구하지 말고 고객 가치에 집중.
  - 클러스터 노드 스토리지보다 데이터 엔지니어링 팀이 병목 현상.
  - 실용적인 리더십으로 데이터 활용법을 교육.

#### 3단계: 데이터로 선도하기

- **데이터 성숙도 3단계**:
  - **자동 배포**: 자동으로 새로운 데이터를 구축 및 배포.
  - **사용자 정의 도구와 시스템 구축**: 경쟁력을 위한 커스텀 도구 개발.
  - **데이터 관리 및 기업적 측면**: 기업 측면에 집중.
  - **데이터 노출 및 전파**:
    - 데이터 카탈로그, 데이터 계보 도구, 메타데이터 관리 시스템을 통해 노출 및 전파.
  - **효율적인 협업**: 엔지니어, 머신러닝 전문가와 협업.
  - **협업 커뮤니티 구축**:
    - 역할이나 직책에 상관없이 커뮤니티 형성.

- **주의깊게 살펴볼 문제**:

  1. **현재 상태 안주**:
     - 2단계에서 현재 상태에 안주하는 것은 큰 위험.
     - 조직이 3단계에 도달하면 유지보수와 개선에 집중.

  2. **기술의 산만함**:
     - 2단계에서 기술의 산만함은 위험 요소.
     - 비즈니스 가치를 제공하지 않는 취미 프로젝트는 피함.
     - 경쟁 우위를 제공할 때만 직접 기술을 활용.

### 1.2.2 데이터 엔지니어의 배경과 기술

- **데이터 엔지니어가 되는 방법**에는 많은 의문점이 있지만 공식화된 경로는 없습니다. 그럼에도 데이터 엔지니어가 성공하기 위해 필수적인 지식은 있습니다.  
- 데이터 엔지니어는 데이터와 기술 모두에 능통해야 합니다:
  - **데이터 측면**: 데이터 관리에 대한 모범 사례 이해.
  - **기술 측면**: 다양한 도구, 옵션, 상호작용, 상충 관계 이해.  
  - **기타 측면**: 소프트웨어 엔지니어링, 데이터 옵스, 데이터 아키텍처에 대한 이해.

- **요약**:
  - 데이터 엔지니어는 데이터 소비자들의 요구사항과 조직의 데이터 전체를 잘 이해해야 합니다.
  - 데이터 엔지니어링은 실용적인 업무이며, 최고의 데이터 엔지니어는 비즈니스와 기술 관점에서 그들의 책임을 판단합니다.

### 1.2.3 비즈니스 책임

- **커뮤니케이션**:
  - 비기술자 및 기술자와의 소통 방법 파악.
  - 조직 전체의 관계 형성과 신뢰 구축이 중요하며, 이는 성공의 핵심입니다.

- **비즈니스 및 제품 요건 이해**:
  - 이러한 요건이 기술로만 해결된다는 믿음은 위험할 정도로 잘못된 생각입니다.
  - 애자일, 데브옵스, 데이터옵스는 조직 전체에 걸친 동의가 필요한 문화적 요소입니다.

- **비용 관리**:
  - 가치 제공과 동시에 비용 절감에 성공하면 훌륭한 성과입니다.
  - 가치, 시간, 총 소유 비용, 기회 비용에 맞게 최적화해야 합니다.
  - 예상치 못한 상황을 방지하기 위해 비용 모니터링 방법을 배우세요.

- **지속적 학습**:
  - 데이터 분야는 빠르게 변화하고 있습니다.
  - 토대가 되는 기본 지식과 새로운 것을 습득하는 능력을 함께 키워야 합니다.
  - 데이터 흐름에 뒤처지지 않고 학습하는 방법을 습득하세요.

 성공적인 데이터 엔지니어는 항상 전체적인 큰 그림을 이해하고 비즈니스 가치를 극대화하는 방법을 파악하고자 한다 커뮤니케이션은 기술자 비기술자 모두에게 필수 요소다 데이터 팀은 다른 이해관계자와의 커뮤니케이션을 바탕으로 성공한 경우가 많으며 따라서 성공이나 실패의 여부가 기술적인 이슈에 따라 결정되는 경우가 거의 없다 조직을 탐색하고 요건을 파악하고 비용을 관리하고 지속해서 학습하는 방법을 알면 경력을 쌓고자 기술적 능력에만 의존한 데이터 엔지니어와 차별화 할 수 있다.


### 1.2.4 기술 책임

- **아키텍처 최적화**: 성능과 비용을 최적화하는 아키텍처 구축 필요.
- **데이터 엔지니어링 수명 주기 지원**:
  - 데이터 생성, 저장, 수집, 변환, 서빙의 각 단계 지원 필요.
  - 보안, 데이터 관리, 옵스, 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링 중요성 강조.

- **전문 기술 요구**: 상용 제품 수준의 소프트웨어 엔지니어링 기술 갖출 것.
  - 고수준 추상화와 코드 파이프라인 작성에 집중.

#### 데이터 엔지니어의 주요 언어

1. **SQL**:
   - 데이터 레이크의 일반적인 인터페이스.
   - 스파크 SQL, 스노우플레이크, 하이브 등 다양한 도구 활용 필요.
   - 데이터 변환 및 분석 문제 신속 해결 가능.
   - 스파크, 프링크 등 프레임워크 내에서 SQL 활용, 최신 SQL 문법 습득 요구.

2. **Python**:
   - 판다스, 넘파이, 에어플로우 등 주요 데이터 도구 기반.
   - 많은 데이터 엔지니어링 도구가 파이썬 API 제공함.

3. **JVM 언어**:
   - 스파크, 하이브, 드루이드 등에서 사용됨.
   - 파이썬보다 성능이 우수하며 저수준 특성에 접근할 수 있음.

4. **Bash**:
   - 리눅스 CLI용 스크립트 작성 및 명령 수행에 필수.
   - Bash 능숙하면 생산성 및 워크플로우 향상됨.

#### 빠르게 변화하는 분야 대응 방법
- **기본 개념 이해**와 **새로운 패러다임 학습** 병행 필요.
- **지속적인 기술 개발**로 업계 흐름 파악 및 적응 요구.


### 1.2.5 A에서 B로 이어진 데이터 엔지니어링 역할의 연속성

데이터 엔지니어링의 역할은 다양하며 모든 데이터 엔지니어가 같은 유형의 작업을 수행하거나 같은 기술을 보유하지 않음. 데이터 성숙도는 기업 내 데이터 역량을 확장함에 따라 직면할 데이터 문제 유형을 이해하는 데 도움을 제공.

#### A형 데이터 엔지니어
- **추상화(Abstraction)**:
  - 차별화되지 않은 과중한 작업을 피하고, 데이터 아키텍처를 가능한 한 추상적이고 단순하게 유지하여 시간 낭비 방지.
  - 주로 시판되는 기성 제품, 관리형 서비스와 도구들을 사용해 데이터 엔지니어링 주기 관리.
  - 데이터 성숙도 수준에 상관없이 산업 전반에 걸쳐 다양한 회사에서 활동.

#### B형 데이터 엔지니어
- **구축(Build)**:
  - 기업의 핵심 역량과 경쟁 우위를 확장하고 활용할 데이터 도구와 시스템 구축.
  - B형 데이터 엔지니어는 데이터 성숙도에서 2단계 및 3단계에 해당하거나 초기 데이터 사용 사례가 독특하고 중요해서 맞춤형 데이터 도구가 필요한 회사에서 자주 발견됨.

#### A형과 B형 데이터 엔지니어의 연계성
- 같은 회사에서 근무하거나 동일 인물일 수도 있음.
- 일반적으로 A형 데이터 엔지니어가 기반 확립을 위해 먼저 채용되며, B형 데이터 엔지니어 기술은 사내에서 필요에 따라 학습하거나 새로운 인재를 고용하여 해결.

## 1.3 조직 내 데이터 엔지니어

### 1.3.1 내부 vs 외부 대면 데이터 엔지니어

- **서비스 대상 이해**:
  - 데이터 엔지니어는 누구에게 서비스를 제공하는지 이해해야 함
  - 주요 업무는 외부 대면, 내부 대면 또는 둘의 혼합일 수 있음

- **외부 대면 데이터 엔지니어**:
  - **역할**: 소셜 미디어 앱, 사물 인터넷, 전자상거래 플랫폼 등 외부 애플리케이션 사용자와 연결함
  - **업무**: 트랜잭션 및 이벤트 데이터를 수집, 저장, 처리하는 시스템을 설계, 구축, 관리함
  - **시스템 특징**: 애플리케이션과 데이터 파이프라인 간 피드백 루프가 있음

- **외부 대면 데이터 엔지니어링의 문제**:
  - **동시성 부하**: 외부 쿼리는 내부 시스템보다 큰 동시성 부하를 처리해야 함
  - **쿼리 제한**: 사용자 쿼리를 제한해 단일 사용자의 인프라 영향을 최소화해야 함
  - **보안 문제**: 보안은 복잡하고 민감하며 특히 멀티테넌트 데이터의 경우 더욱 그렇다

- **내부 대면 데이터 엔지니어**:
  - **집중 영역**: 비즈니스 및 내부 이해관계자의 요구 사항에 집중함
  - **업무**: BI 대시보드, 보고서, 데이터 과학, 머신러닝 모델용 데이터 파이프라인, 데이터 웨어하우스의 생성 및 유지보수를 담당함

- **혼합 업무**:
  - 외부 및 내부 대면 업무는 혼합될 수 있음
  - 데이터 엔지니어는 쿼리 동시성이나 보안 등 요구 사항이 다른 두 그룹을 관리해야 함

### 1.3.2 데이터 엔지니어와 기타 기술 역할

- **업스트림 데이터 생산자**:
  - **소프트웨어 엔지니어**: 비즈니스를 운영하는 소프트웨어와 시스템을 구축하며, 데이터 엔지니어가 사용하는 내부 데이터의 생성에 큰 책임을 가짐. 주로 애플리케이션 이벤트 및 로그 데이터를 생성하며, 데이터 엔지니어와 협력해 신규 프로젝트 초기에 어플리케이션 데이터를 설계
  - **데이터 아키텍트**: 조직의 데이터 관리를 위한 청사진을 설계하며, 데이터 관리와 거버넌스 정책을 수립하고, 전사적인 데이터 관리 전략을 조율. 클라우드 마이그레이션과 신규 클라우드 설계에 핵심적인 역할을 담당
  - **데브옵스 및 사이트 신뢰성 엔지니어**: 운영 모니터링을 통해 데이터를 생성하며, 업스트림 이해관계자로 분류되지만 데이터 시스템 운영을 조정할 때 데이터 엔지니어와 소통하는 다운스트림 역할도 함

- **다운스트림 데이터 소비자**:
  - **데이터 분석가**: 비즈니스 성과와 동향을 파악하기 위해 데이터 웨어하우스나 데이터 레이크에서 SQL 쿼리를 실행하고 스프레드시트나 다양한 BI 도구를 활용. 비즈니스 사용자, 경영진 및 임원 등의 니즈에 맞춰 데이터를 분석하며, 데이터 엔지니어와 협력해 필요한 데이터 원천 파이프라인을 구축
  - **데이터 과학자**: 예측과 추천을 위한 미래지향적인 모델을 구축하며, 데이터 수집, 정제, 준비에 전체 업무 시간의 70-80%를 소모. 확장 가능한 프레임워크가 없다면 데이터 다운샘플링으로 인한 데이터 품질 저하의 위험이 있음. 데이터 엔지니어는 데이터 과학자의 작업 경로를 최적화하여 작업 결과물을 더 쉽게 만들 수 있도록 지원
  - **머신러닝 엔지니어 및 인공지능 연구원**: 고급 머신러닝 기술을 개발하고 모델을 훈련하며, 확장된 운영 환경에서 머신러닝 프로세스를 실행하는 인프라를 설계 및 유지. 딥러닝 프레임워크에 대한 전문 지식을 갖추고 있으며, 데이터 과학자와 협력해 고급 머신러닝 프로세스를 설계

- **데이터 엔지니어의 허브 역할**:
  - 데이터 생산자와 소비자 사이의 허브 역할을 수행하며, 생산과 소비 간 피드백 루프를 관리. 운영 역할을 담당하는 데브옵스 엔지니어와도 소통하며 데이터 시스템 전반을 관리

#### 업스트림 이해관계자

- **데이터 아키텍트**:
  - 데이터 엔지니어와 유사한 추상화 수준에서 작업하며, 조직 데이터 관리를 위한 청사진을 설계
  - 데이터 아키텍처 및 시스템을 맵핑하여 프로세스 전체를 감독
  - 기술적 및 비기술적 측면을 연결하는 가교 역할을 수행
  - 데이터 관리 및 거버넌스 정책을 수립하고 전사적인 전략을 조율
  - 클라우드 마이그레이션과 신규 클라우드 설계에 핵심적인 역할을 담당

- **소프트웨어 엔지니어**:
  - 비즈니스에 필요한 소프트웨어와 시스템을 구축
  - 내부 데이터의 생성 업무를 책임지고, 애플리케이션 이벤트 및 로그 데이터 제공
  - 데이터 엔지니어와 협력해 신규 프로젝트의 초기 단계부터 애플리케이션 데이터를 설계
  - 애플리케이션 데이터의 양, 빈도, 형식, 보완 및 규정 준수 등 데이터 엔지니어링 수명 주기에 영향을 미치는 모든 요소를 파악

- **데브옵스 엔지니어 및 사이트 신뢰성 엔지니어**:
  - 운영 모니터링을 통해 데이터를 생성하며, 데이터 엔지니어의 업스트림 역할을 수행
  - 때로는 데이터 시스템 운영을 조정하며 데이터 엔지니어와 직접 소통하는 다운스트림 역할도 수행

#### 다운스트림 이해관계자

- **다양한 역할**:
  - 데이터 엔지니어가 다운스트림 역할과 소통하는 방법을 다룸
  - 중앙집중식 데이터 엔지니어링 팀 및 서비스 모델도 소개



- 데이터 과학자

  - **모델 구축**:
    - 미래지향적인 예측 및 추천 모델 구축
    - 데이터 수집, 정제, 준비에 업무 시간의 70~80%를 소비

  - **병목 현상과 품질 저하 문제**:
    - 단일 워크스테이션에서 작업 시 데이터 다운샘플링이 발생하며 모델 품질 저하 가능
    - 로컬에서 개발한 코드는 실제 운용 환경 배포에 어려움이 있음
    - 자동화 부족 시 데이터 워크플로우 방해

  - **제품 단계 데이터 과학의 필요성**:
    - 데이터 전문가의 역할을 강조
    - 데이터 엔지니어가 데이터 과학자의 작업 결과물을 제작할 경로를 설정할 수 있도록 지원해야 함

- 데이터 분석가

  - **업무 및 도구**:
    - 비즈니스 성과와 동향 파악
    - 데이터 웨어하우스나 데이터 레이크에서 SQL 쿼리 실행
    - 계산 및 분석에 스프레드시트, BI 도구 사용
    - 주요 고객은 비즈니스 사용자, 경영진, 임원

  - **협업**:
    - 데이터 엔지니어와 협업해 새로운 데이터 원천용 파이프라인 구축
    - 주제별 전문 지식으로 데이터 품질 개선에 기여

- 머신러닝 엔지니어 및 인공지능 연구원

  - **역할 및 전문성**:
    - 데이터 엔지니어, 데이터 과학자와 겹치는 부분이 많음
    - 고급 머신러닝 기술 개발, 모델 훈련, 인프라 설계 및 유지
    - 파이토치, 텐서플로우 등 딥러닝 프레임워크에 대한 실무 지식 보유

  - **운영 환경**:
    - 모델 훈련과 배포에 필요한 하드웨어, 서비스 및 시스템 이해
    - 머신러닝 시스템 운영 환경에 책임을 질 수 있음

  - **경계의 모호함**:
    - 머신러닝 엔지니어링, 데이터 엔지니어링, 데이터 과학 사이 경계가 모호함
    - 데이터 엔지니어와 긴밀히 협업하여 고급 머신러닝 프로세스를 설계

### 1.3.3 데이터 엔지니어와 비즈니스 리더십
  - 기업은 데이터 활용을 확대하며 데이터 엔지니어는 전략적 계획에 참여하고 IT를 넘어 주요 이니셔티브를 주도함
  - 데이터 아키텍트를 지원하며 비즈니스와 데이터 과학, 분석의 결합체로서 역할 수행

- **데이터 엔지니어와 프로젝트 매니저**
  - **역할**:
    - 데이터 엔지니어는 클라우드 마이그레이션, 차세대 데이터 아키텍처 구축 등 장기 프로젝트에 참여
    - 신규 프로젝트에서 최적의 아키텍처 및 도구 선택, 새로운 데이터 아키텍처 구성
    
  - **프로젝트 매니저와의 협업**:
    - 데이터 엔지니어는 인프라 및 서비스 제공에 능력을 발휘
    - 프로젝트 매니저는 트래픽 총괄, 게이트키퍼 역할, 애자일·스크럼 방식 운영
    - 중요한 성과물에 우선순위 부여

- **데이터 엔지니어와 제품 관리자**
  - **역할**:
    - 제품 관리자는 제품 개발 감독 및 제품 라인 관리
    - 데이터 엔지니어는 제품 관리자와 협력해 데이터 제품 개발
    
  - **균형 조절**:
    - 제품 관리자는 기술팀과 고객, 비즈니스 요구 간 균형을 유지
    - 프로젝트 매니저처럼 데이터 엔지니어와의 협업 중요

- **다른 매니저와의 협업**
  - 데이터 엔지니어는 프로젝트 매니저 및 제품 관리자 외에도 다양한 매니저와 소통
  - 일반적으로 서비스 또는 교차 기능 모델을 따르며 다양한 요청을 처리
  - 특정 관리자, 프로젝트 또는 제품에 할당된 자원으로 작업


## 1.4 결론

1장에서는 데이터 엔지니어링 환경의 개요를 다음과 같이 간략하게 설명했다

- **데이터 엔지니어링의 정의와 역할**:
  - 데이터 엔지니어링이란 무엇인지와 데이터 엔지니어가 하는 일에 대해 설명

- **기업의 데이터 성숙도 유형**:
  - 기업의 데이터 성숙도 유형과 그 차이를 이해

- **A형과 B형 데이터 엔지니어**:
  - 두 유형의 데이터 엔지니어 특성과 역할 비교

- **데이터 엔지니어 협업 대상**:
  - 데이터 엔지니어가 협업하는 업스트림 및 다운스트림 이해관계자, 프로젝트 매니저, 제품 관리자 등 다양한 역할 소개

# 2 데이터 엔지니어링 수명 주기

## 2.1 데이터 엔지니어링 수명 주기란?

데이터 엔지니어링 수명 주기는 다음 5단계로 나눌 수 있다:
- **데이터 생성**
- **데이터 수정**
- **데이터 수집**
- **데이터 변환**
- **데이터 서빙**

데이터 저장은 수명 주기 전체에 걸쳐 일어난다. 데이터의 흐름은 깔끔하고 일정하지 않으며 수명 주기의 여러 단계가 반복, 순서가 어긋나거나 겹치기도 한다. 예상치 못한 방식으로 조합될 수 있다.

이 수명 주기에는 여러 필수 요소가 전반에 걸쳐 존재한다:
- **보안**
- **데이터 관리**
- **데이터 옵스**
- **데이터 아키텍처**
- **오케스트레이션**
- **소프트웨어 엔지니어링**

이러한 요소가 없다면 수명 주기의 어떤 부분도 제대로 작동하지 않는다.

### 2.1.1 데이터 생성

원천 시스템은 데이터 엔지니어링 수명 주기에서 사용되는 데이터의 원본이다. 원천 시스템은 예를 들어 IoT 장치, 어플리케이션, 메시지 대기열, 트랜잭션 데이터베이스 등이 될 수 있다. 데이터 엔지니어는 원천 시스템의 데이터를 사용하지만, 원천 시스템 자체를 소유하거나 제어하지 않는다. 이들은 데이터 생성 방식, 데이터 빈도 및 속도, 생성되는 데이터의 다양성을 잘 이해해야 한다.

데이터 엔지니어는 원천 시스템 소유자와 개방적인 소통 라인을 유지해 변경 사항이 파이프라인과 분석에 영향을 주지 않도록 해야 한다. 데이터 엔지니어가 이해해야 하는 다양한 데이터 원천 시스템이 있기 때문에, 이를 평가할 때 주요 고려 사항은 다음과 같다:

- **데이터 원천의 특성**: 원천이 어플리케이션인가, IoT 장치인가?
- **데이터 유지 방식**: 데이터가 오래 보존되는가, 아니면 일시적이고 빠르게 삭제되는가?
- **데이터 일관성**: 출력 데이터에서 어느 정도 일관성을 기대할 수 있는가? 데이터 품질 검사를 실행할 때 오류 데이터나 이상치가 얼마나 자주 나타나는가?
- **에러 빈도**: 데이터 에러는 얼마나 자주 발생하는가?
- **중복 여부**: 데이터의 중복이 있는가?
- **지연 도착**: 일부 데이터 값이 다른 메시지보다 훨씬 늦게 도착할 수 있는가?
- **데이터 스키마**: 데이터 엔지니어가 완전히 파악하려면 여러 테이블 또는 시스템 간의 조인이 필요한가?
- **스키마 변경**: 스키마가 변경되면 어떻게 대처하고 다음 스트림 이해관계자에게 전달할 것인가?
- **데이터 수집 빈도**: 원천 시스템의 데이터를 얼마나 자주 가져와야 하는가?
- **상태 있는 시스템**: 데이터가 정기적인 스냅샷으로 제공되는가, 아니면 변경 데이터 캡처 이벤트로 제공되는가? 변경 사항은 어떻게 추적되는가?
- **업스트림 의존성**: 원천 시스템에 업스트림 데이터 의존 관계가 있는가? 해당 시스템의 특성은 무엇인가?
- **데이터 품질 검사**: 늦거나 누락된 데이터를 확인하기 위한 데이터 품질 검사가 실시되고 있는가?
---
- **원천 시스템의 한계 이해**:
  - 데이터 엔지니어는 원천 어플리케이션에서 분석 쿼리가 자원 경험 및 성능 문제를 일으킬 수 있는지 이해해야 함. 원천 어플리케이션의 분석 작업이 시스템 성능에 영향을 미칠 수 있으므로, 이를 고려한 데이터 처리 방법이 필요함.

- **원천 데이터의 스키마 처리 방식**:
  - 원천 시스템은 데이터의 스키마를 다양한 방식으로 처리할 수 있음. 주요 방식으로는 스키마리스 방식과 고정 스키마 방식이 있음.
  
  - **스키마리스 방식**:
    - 예: 몽고DB와 같은 도큐먼트 데이터베이스에서 사용. 데이터 기록 시 스키마를 따로 정의하지 않으며, 데이터 자체에 스키마 정보를 포함시킬 수 있음.
  
  - **고정 스키마 방식**:
    - 관계형 데이터베이스 스토리지를 사용하는 경우, 데이터베이스에 적용된 고정된 스키마를 따라야 함. 어플리케이션 쓰기 작업은 이 스키마를 준수해야 함.

- **스키마의 진화**:
  - 스키마는 시간이 지남에 따라 변할 수 있음. 데이터 엔지니어의 주요 작업 중 하나는 원천 시스템의 스키마에서 원시 데이터를 받아 분석에 유용한 형태로 변환하는 것임.
  - 원천 스키마가 진화함에 따라 데이터를 적절히 처리하고 변환하는 작업이 더욱 복잡해질 수 있음.

### 2.1.3 데이터 저장

데이터 저장에 대한 몇 가지 주요 고려 사항은 다음과 같습니다:

1. **클라우드 데이터 아키텍처**:
   - 여러 스토리지 솔루션을 활용함.
   - 순수 스토리지뿐만 아니라 복잡한 데이터 변환을 지원하는 경우가 많음.
   - 데이터 수명 주기의 여러 단계에 참여함 (수집, 변환, 서비스 제공 등).

2. **스토리지 시스템 평가: 주요 엔지니어링 고려 사항**:
   - **쓰기 및 읽기 속도**:
     - 스토리지가 아키텍처가 요구하는 쓰기 및 읽기 속도를 충족하는지 확인.
     - 스토리지가 다운스트림 프로세스의 병목 현상을 초래하지 않는지 확인.

   - **작동 방식 이해**:
     - 스토리지 시스템이 작동 방식을 인지하고 최적으로 활용하는지 확인.
     - 객체 스토리지 시스템에 과도한 접근 및 갱신이 적용되지 않도록 주의.

   - **확장성**:
     - 향후 예상되는 확장을 처리할 수 있는지 평가.
     - 용량 제한을 고려하고 읽기 속도, 쓰기 볼륨 등도 함께 고려.

   - **메타데이터 캡처**:
     - 스키마 진화, 데이터 흐름, 데이터 계보 등에 대한 메타데이터를 캡처.
     - 메타데이터는 검색 기능과 제도적 지식을 향상시켜 미래 프로젝트 및 아키텍처 변경을 간소화.

   - **쿼리 패턴 지원**:
     - 순수 스토리지 솔루션인지, 복잡한 쿼리 패턴을 지원하는지 확인.

   - **스키마 적합성**:
     - 스키마에 유연성이 있는지 확인. 강제된 스키마는 유연성을 저해할 수 있음.

   - **데이터 거버넌스**:
     - 마스터 데이터, 골든 레코드, 데이터 품질, 데이터 계보를 어떻게 추적하는지 확인.

   - **법령 준수**:
     - 특정 지리적 위치에만 데이터를 저장하고 다른 곳에는 저장하지 않을 수 있는가? 데이터 주권과 법령 준수를 위한 전략을 수립.


---
#### 데이터 접근 빈도 이해

데이터 접근 빈도에 따라 데이터의 온도가 결정됩니다:

- **핫 데이터**: 가장 자주 액세스되는 데이터.
- **미온적 데이터**: 가끔씩만 액세스되는 데이터.
- **콜드 데이터**: 거의 액세스되지 않으며, 아카이브 시스템에 저장하기에 적합. 규정 준수 목적으로 보관되거나, 장애 시 복구를 위해 사용될 수 있음.

#### 스토리지 시스템 선택

어떤 유형의 스토리지 솔루션을 선택해야 할까요? 이에 대한 결정은 여러 요소에 따라 달라집니다:

- **사용 사례**: 데이터 수집 및 액세스 방식에 따라 스토리지 요구 사항이 달라짐.
- **데이터 볼륨**: 데이터의 총량에 따라 스토리지 크기와 비용이 영향을 받음.
- **수집 빈도**: 데이터가 얼마나 자주 수집되는지에 따라 스토리지 시스템의 성능 요구 사항이 결정됨.
- **데이터 형식 및 크기**: 구조화된 데이터와 비구조화된 데이터의 차이, 데이터 파일 크기에 따른 스토리지 전략이 필요함.

모든 스토리지 기술은 장단점, 즉 트레이드오프가 있습니다. 수많은 스토리지 기술 중 데이터 아키텍처에 가장 적합한 옵션을 찾을 때는 이런 점을 고려해야 합니다.

### 2.1.4 데이터 수집

데이터 원천과 사용 중인 원천 시스템의 특징 및 데이터 저장 방법을 이해한 후, 데이터를 수집하는 것이 중요합니다. 데이터 엔지니어링 수명 주기의 다음 단계는 원천 시스템에서 데이터를 수집하는 것입니다.

원천 시스템은 직접 관리하기 어렵고, 응답하지 않거나 품질이 낮은 데이터를 제공할 수 있습니다. 또한 여러 이유로 데이터 수집 서비스가 제대로 작동하지 않아 데이터 흐름이 멈추거나 필요한 데이터가 충분히 제공되지 않을 수 있습니다.

#### **수집 단계의 주요 엔지니어링 고려 사항:**
- **사용 사례**: 수집 중인 데이터의 사용 사례는 무엇인가? 여러 버전의 데이터셋을 생성하는 대신 재사용이 가능한가?
- **데이터 목적지**: 수집 후 데이터의 최종 목적지는 어디인가?
- **접근 빈도**: 데이터에 얼마나 자주 접근해야 하는가?
- **데이터 용량**: 데이터는 보통 어떤 용량으로 도착하는가?
- **데이터 형식**: 데이터 형식은 무엇이며, 다운스트림 시스템에서 처리할 수 있는가?
- **유효 상태**: 원천 데이터는 다운스트림에서 바로 사용할 수 있는 유효 상태인가? 사용 기간과 사용 불가능해지는 주요 요인은 무엇인가?
- **데이터 변환**: 데이터가 스트리밍 소스에서 전송되면, 목적지에 도달하기 전에 변환이 필요한가? 스트리밍 자체에서 변환하는 것이 적절한가?


#### **배치 vs 스트리밍**

- **스트리밍**:
  - 우리가 다루는 대부분의 데이터는 본질적으로 스트리밍 방식입니다.
  - 스트리밍 수집을 통해 다른 애플리케이션, 데이터베이스, 분석 시스템 등 다운스트림 시스템에 데이터를 실시간으로 연속해 제공할 수 있습니다.
  - **실시간**이란 데이터가 생성된 지 얼마 지나지 않은 짧은 시간 내에 다운스트림 시스템에서 데이터를 사용할 수 있는 것을 의미합니다.

- **배치**:
  - 배치 데이터는 미리 설정된 시간 간격이나 크기 임계값에 도달하면 수집됩니다.
  - 배치 수집은 한 방향으로만 진행되며, 데이터가 배치로 분할되면 다운스트림 소비자의 지연 시간이 제한됩니다.
  - 배치 처리는 분석 및 머신러닝에 다운스트림을 사용할 때 매우 인기 있는 방법입니다.

#### 배치와 스트림 수집의 주요 고려 사항

1. **실시간 데이터 처리**:
   - 데이터를 실시간으로 수집할 경우, 다운스트림 스토리지 시스템이 데이터 흐름 속도를 처리할 수 있는가?

2. **실시간 데이터 필요성**:
   - 밀리초 단위의 실시간 데이터가 필요한가? 아니면 매분 데이터를 축적하는 마이크로 배치 접근이 더 효과적인가?

3. **스트리밍 수집의 이점**:
   - 스트리밍 수집을 통해 얻을 수 있는 구체적인 이점은 무엇인가?
   - 데이터를 실시간으로 수집함으로써 배치 방식에 비해 개선될 수 있는 부분은 무엇인가?

4. **비용과 유지보수**:
   - 스트리밍 방식이 배치 방식보다 시간, 비용, 유지보수, 다운타임, 기회 비용 측면에서 더 많은 비용을 소모하는가?

5. **안정성과 다중화**:
   - 인프라에 장애가 발생할 때, 스트리밍 파이프라인과 시스템은 안정적이고 다중화되어 있는가?

6. **적합한 도구 선택**:
   - 관리형 서비스를 사용할지, 자체 인프라로 Kafka, Flink, Spark, Pulsar 등의 인스턴스를 구축할지 결정해야 함.
   - 관리 비용과 이점은 무엇인가?

7. **머신러닝 활용**:
   - 머신러닝 모델을 배포할 때 온라인 예측 및 지속적인 훈련으로 얻을 수 있는 이점은 무엇인가?

8. **원천 시스템 영향**:
   - 실 운영 인스턴스에서 데이터를 가져올 경우, 수집 프로세스가 원천 시스템에 미칠 영향은 얼마나 될까?

**결론**:
- 스트리밍 수집 방식은 좋은 아이디어처럼 보일 수 있지만, 추가 비용과 복잡성이 발생할 수 있습니다.
- 배치 및 마이크로 배치 수집 프레임워크는 효율적일 수 있습니다.
- 배치 사용의 트레이드오프를 이해하고 비즈니스 사용 사례를 정확하게 파악한 후에 스트리밍 수집 방식을 채택하는 것이 좋습니다.


### 2.1.5 데이터 변환

데이터를 수집하고 저장한 후, 이를 활용하기 위해 데이터 엔지니어링 수명 주기의 다음 단계인 **변환**을 진행해야 합니다. 데이터를 원래의 형태에서 다운스트림 사용 사례에 유용한 형태로 변경함으로써, 데이터가 가치 있는 정보로 변모하는 시작 단계입니다.

1. **기본 변환**:
   - 데이터를 올바른 형태로 맵핑하고, 레코드를 표준 형식으로 지정하며, 잘못된 유형은 제거.
   - 이후 단계에서는 데이터 스키마를 변환하고 정규화.

2. **변환 단계에서의 주요 고려 사항**:
   - **비용과 ROI**:
     - 변환 비용과 투자 수익률을 고려하고, 이와 관련된 비즈니스 가치는 무엇인가?

   - **단순하고 독립적**:
     - 변환 작업은 가능한 한 단순하고 독립적인지 고려.

   - **비즈니스 규칙**:
     - 변환이 어떤 비즈니스 규칙을 지원하는지 파악.

3. **배치 vs 스트리밍 변환**:
   - **배치 변환**: 여전히 압도적으로 인기 있지만, 스트리밍 데이터의 증가에 따라 스트리밍 변환도 계속 인기를 얻고 있습니다.
   - **스트리밍 변환**: 특정 도메인에서 배치 처리를 완전히 대체할 가능성이 있음.

4. **변환의 일반적 위치**:
   - **원천 시스템에서 변환**: 데이터 수집 중에 변환되거나 스트리밍 파이프라인 내에서 추가 필드와 계산을 통해 보강.
   - **다양한 위치**: 데이터 준비, 정규화 등 여러 작업을 통해 최종 소비자에게 가치를 더함.

5. **비즈니스 로직과 모델링**:
   - 데이터 변환의 주요 원인 중 하나는 비즈니스 로직.
   - 비즈니스 프로세스를 명확하고 최신화하려면 데이터 모델링이 중요.
   - 변환 전반에 걸쳐 비즈니스 로직을 표준 접근 방식으로 구현.

### 2.1.6 데이터 서빙

데이터 엔지니어링 수명 주기의 마지막 단계입니다. 이 단계에서는 데이터를 활용하여 가치를 창출합니다. 데이터로부터의 가치는 사용자마다 다르게 해석되지만, 소비되지 않는 데이터는 비활성 상태로 남게 됩니다. **데이터 레이크** 프로젝트로 인해 대규모의 데이터셋이 수집되어도, 이것이 적극적으로 활용되지 않으면 기업에 부담이 될 수 있습니다. 클라우드 시대의 데이터 프로젝트는 새로운 비즈니스 프로젝트를 위해 모던 데이터 웨어하우스, 객체 스토리지 시스템, 스트리밍 기술을 사용합니다.

**분석**  
분석은 대부분의 데이터 작업에서 핵심적인 역할을 하며, 데이터가 저장 및 변환된 후 보고서와 대시보드를 생성하고 임시 분석을 수행할 수 있습니다. 분석에는 다음과 같은 여러 종류가 있습니다:

- **비즈니스 인텔리전스**:  
  기업 경영의 과거와 현재 상태를 설명하기 위해 데이터를 수집하며, 이를 처리하는 비즈니스 로직과 정의를 유지 및 관리합니다. 비즈니스 로직은 데이터 웨어하우스를 쿼리하는 데 사용되어 보고서 및 대시보드가 기업의 정의와 일치하도록 합니다. 기업의 데이터 성숙도가 높아짐에 따라 비즈니스 사용자도 셀프 서비스 분석을 통해 직접 데이터를 분석하고 통찰력을 얻을 수 있습니다.

- **운영 분석**:  
  운영의 세부 사항을 중점으로 보고서 사용자와 함께 작업을 촉진합니다. 웹사이트나 애플리케이션 상태에 대한 실시간 대시보드를 제공하며, 원천 시스템이나 스트리밍 데이터 파이프라인에서 실시간으로 소비할 수 있습니다.

**머신러닝**  
조직이 높은 데이터 성숙도에 도달하면 머신러닝을 중심으로 문제를 파악하고 업무를 구성할 수 있습니다. 데이터 엔지니어링과 머신러닝의 경계가 모호해질 수 있지만, 다음을 지원해야 합니다:

- **스파크 클러스터**:  
  분석 파이프라인과 머신러닝 모델 훈련을 지원합니다.

- **메타데이터 및 카탈로그 시스템**:  
  데이터 기록과 계보를 추적하는 시스템을 제공하며, 팀 간 작업을 조정합니다.

- **특성 저장소**:  
  데이터 엔지니어링과 머신러닝 엔지니어링을 결합한 최신 도구로, 특성 이력과 버전을 유지하고 팀 간 특성을 공유하며 기본적인 운영과 조정 기능을 제공합니다.

데이터 엔지니어는 기본 머신러닝 기술, 데이터 처리 요구사항, 회사 내 모델의 사용 사례를 파악하고, 분석 팀과의 협업 능력을 갖춰야 합니다. 이를 통해 데이터 처리에 대해 효율적인 커뮤니케이션을 유지하고 협업을 촉진할 수 있습니다. 데이터 엔지니어는 다른 팀과 협력하여 도구를 구축할 수 있는 이상적인 인재입니다.

#### - 머신러닝 관련 데이터 서빙 단계에서 고려할 사항

1. **데이터 품질**:  
   신뢰할 수 있는 특성 엔지니어링을 수행하기에 충분한 품질의 데이터인지 확인해야 합니다. 데이터의 품질 요구 사항 및 평가는 데이터를 사용하는 팀과 긴밀하게 협력해 개발됩니다.

2. **데이터 검색 가능성**:  
   데이터 과학자와 머신러닝 엔지니어가 쉽게 접근하고 활용할 수 있도록 데이터의 검색 가능성을 확보해야 합니다.

3. **기술적 및 조직적 경계**:  
   데이터 엔지니어링과 머신러닝 엔지니어링 간의 기술적 및 조직적 경계가 명확해야 합니다. 이러한 조직 차원의 질문이 아키텍처에 큰 영향을 미칠 수 있습니다.

4. **데이터 편향 여부**:  
   데이터셋이 실제 상황을 제대로 나타내고 있는지, 특정한 편향이 존재하지는 않는지 점검해야 합니다.

머신러닝에 막대한 자원을 투자하기 전에, 신중하게 데이터를 기반으로 구축된 시스템을 만들어야 합니다. 이는 데이터 엔지니어링과 머신러닝 수명 주기 전체에 걸쳐 최적의 시스템과 인프라를 구성하는 것이 중요하다는 뜻입니다. 일반적으로 머신러닝으로 전환하기 전에 분석 역량을 충분히 개발하는 것이 가장 좋습니다.
## 2.2 데이터 엔지니어링 수명 주기의 드러나지 않는 주요 요소

### **2.2.1 보안**

- **최소 권한 원칙**:  
  데이터 엔지니어는 보안을 최우선으로 생각해야 하며, 데이터와 접근 보안을 모두 이해하고 최소 권한 원칙을 준수해야 합니다. 모든 사용자에게 관리자 권한을 부여하는 것은 위험한 행위이므로, 현재 업무를 수행하는 데 필요한 접근 권한만 부여해야 합니다.

- **안전한 작업 습관**:  
  표준 사용자 접근 권한을 가진 가시적인 파일을 찾을 때는 root shell을 사용하지 않으며, 낮은 테이블을 관리할 때 데이터베이스의 슈퍼 유저 권한을 사용하지 않습니다. 이러한 습관으로 최소 권한 원칙을 준수하며 사고 예방과 안전 제일의 사고방식을 유지할 수 있습니다.

- **데이터 접근 관리**:  
  사람과 시스템에 필요한 기간 동안에만 정확하게 데이터 접근을 제공해야 합니다. 암호화, 토큰화, 데이터 마스킹, 난독화 등을 활용해 저장된 데이터와 사용 중인 데이터를 모두 보호하며, 단순하고 견고한 접근 제어를 유지해야 합니다.

- **보안 지식 확장**:  
  데이터 엔지니어는 클라우드 및 온프레미스 환경에 대한 모범 사례를 이해하고, 사용자 및 아이디 접근 관리의 역할, 정책, 그룹, 네트워크 보안, 암호화 등을 다룰 수 있는 유능한 보안 관리자여야 합니다. 보안 관련 지식을 쌓기 위한 좋은 출발점으로 고려해보세요.

### 2.2.2 데이터 관리

- **DMBoK 정의**:  
  데이터 관리 지식 책 DMBoK에 따르면, 데이터 관리는 수명 주기 전체에 걸쳐 데이터와 정보 자산의 가치를 제공, 제어, 보호, 향상하기 위한 계획, 정책, 프로그램, 사례를 개발, 실행 및 감독하는 것입니다.

- **데이터 관리의 중요성**:  
  데이터 엔지니어는 수명 주기 전반에 걸쳐 데이터를 관리하고, 데이터 관리에는 다음과 같은 측면들이 포함됩니다:

  - **데이터 거버넌스**:  
    발견 가능성과 책임을 다루는 데이터 거버넌스.

  - **데이터 모델링 및 설계**:  
    효율적인 데이터 모델링과 설계.

  - **데이터 계보**:  
    데이터 계보 추적.

  - **저장 및 운영**:  
    데이터 저장과 운영 관리.

  - **데이터 통합 및 상호 운용성**:  
    다양한 시스템 간 데이터 통합과 상호 운용성.

  - **데이터 수명 주기 관리**:  
    수명 주기 전반에 걸친 데이터 관리.

  - **고급 분석 및 머신 러닝**:  
    고급 분석 및 머신러닝을 위한 데이터 시스템.

  - **윤리 및 개인 정보 보호**:  
    데이터의 윤리적 사용과 개인 정보 보호.

#### 데이터 거버넌스
- **정의**:  
  데이터 거버넌스는 조직이 수집한 데이터의 품질, 무결성, 보안, 사용성을 보장하는 기능입니다. 이를 통해 조직 전체의 데이터 가치를 극대화하면서 적절한 보안 제어로 데이터를 보호할 수 있습니다.

- **중요성**:  
  우발적이거나 무계획적인 데이터 거버넌스는 보안 침해 등 다양한 부작용을 초래할 수 있습니다. 그러나 의도적인 접근을 통해 조직의 데이터 역량과 데이터 가치를 극대화할 수 있습니다.

- **핵심 범주**:  
  데이터 거버넌스의 핵심 범주는 다음과 같습니다:
  - **발견 가능성**:  
    데이터를 쉽게 검색하고 사용할 수 있어야 합니다. 사용자는 필요한 데이터에 신속하고 안정적으로 접근하며 데이터의 출처, 관계, 의미를 이해해야 합니다.

  - **보안**:  
    데이터를 보호하기 위한 적절한 보안 정책을 유지해야 합니다.

  - **책임**:  
    데이터 사용과 관련된 책임을 명확히 해야 합니다.

##### 메타데이터
- **정의**:  
  메타데이터는 데이터에 대한 데이터로, 데이터를 검색하고 제어하는 데 필수적입니다.

- **분류**:  
  메타데이터는 크게 자동 생성 데이터와 인간 생성 데이터로 나뉩니다. 자동화가 일반적이지만, 수작업으로 수집된 메타데이터는 오류가 발생하기 쉽습니다.

- **도구**:  
  데이터 카탈로그, 데이터 계보 추적 시스템, 메타데이터 관리 도구 등을 통해 데이터베이스를 탐색하고 관계를 파악하며, 데이터 파이프라인을 모니터링해 데이터의 출처와 타깃을 추적할 수 있습니다.

- **사회적 요소**:  
  메타데이터에는 사회적 요소가 포함됩니다. 조직은 프로세스, 데이터셋, 파이프라인에 대한 지식을 축적하며, 메타데이터 시스템은 이러한 사회적 측면에 초점을 맞춰야 합니다.

- **활용**:  
  메타데이터 시스템과 프로세스를 통해 데이터 엔지니어는 메타데이터를 수명 주기 전체에 걸쳐 파이프라인 설계와 데이터 관리에 활용할 수 있습니다.

##### DMBOK에서 식별한 메타데이터의 네 가지 주요 범주

1. **비즈니스 메타데이터**  
   - **내용**: 비즈니스 및 데이터 정의, 데이터 규칙과 로직, 데이터 사용 방법과 장소, 데이터 소유자 등과 관련된 정보를 포함.
   - **용도**: 데이터 엔지니어가 데이터 사용의 콘텍스트와 정의를 파악하여 적절하게 활용할 수 있도록 도움.

2. **기술 메타데이터**  
   - **내용**: 데이터 모델과 스키마, 데이터 계보, 필드 맵핑, 파이프라인 워크플로우 등의 정보를 담고 있음.
   - **용도**: 데이터 엔지니어가 시스템을 생성하고 연결하며, 전체 수명 주기를 모니터링하는 데 사용.
   - **일반 유형**
     - **파이프라인 메타데이터**: 워크플로우 일정, 데이터 종속성, 구성 세부 정보 등.
     - **데이터 계보 메타데이터**: 데이터 원본 및 변형 기록을 추적하고 데이터 간 관계를 나타냄.
     - **스키마 메타데이터**: 데이터 구조를 설명하며 시스템에 저장된 데이터를 나타냄.

3. **운영 메타데이터**  
   - **내용**: 시스템의 운영 결과와 관련된 정보로, 프로세스 작업, 애플리케이션 런타임 로그, 오류 로그 등을 포함.
   - **용도**: 데이터 엔지니어가 프로세스 성공 또는 실패 여부를 판단하고, 관련된 데이터를 식별할 수 있도록 도움.
   - **특징**: 오케스트레이션 시스템에서는 제한된 정보를 제공하지만, 운영 메타데이터는 분산 경향이 있음.

4. **참조 메타데이터**  
   - **내용**: 다른 데이터를 분류하는 데 필요한 데이터로 조회 데이터로도 불림. 내부 코드, 지리적 코드, 특정 단위, 내부 달력 표준 등이 이에 포함.
   - **특징**: 대부분의 참조 데이터는 내부적으로 관리되지만, 외부 표준을 사용할 수도 있음. 시간이 지나도 서서히 변경되는 경향이 있음.

##### 데이터 책임
- **의미**: 데이터의 일부를 관리할 개인을 지정하는 것. 이 책임자는 다른 이해 관계자의 거버넌스 활동을 조정하며, 데이터 책임은 다양한 수준에서 발생할 수 있음.
  - 예: 테이블 또는 로그 스트림 수준, 단일 필드 엔티티 등.

- **데이터 품질**
  - 데이터가 비즈니스 메타데이터의 기대치에 부합하는지 검토하는 것이 핵심.
  - 데이터 품질 테스트를 통해 스키마 기대치, 데이터 완전성, 정밀도 등에 대한 준수를 보장.

- **주요 특징**
  - **정확도**: 수집된 데이터가 정확한지, 중복된 값이 없는지, 수치가 정확한지 확인.
  - **완전성**: 모든 필수 필드에 유효한 값이 포함되어 있는지 확인.
  - **적시성**: 데이터를 적시에 이용할 수 있는지 확인.

##### 마스터 데이터 관리(MDM)
- **마스터 데이터**: 직원, 고객, 제품, 위치 등 비즈니스 엔티티에 관한 데이터.
- **마스터 데이터 관리**:
  - **골든 레코드**: 조직 및 파트너 간에 일관된 엔티티 정의를 구축하는 관행.
  - **역할**: 조직 내 엔티티 데이터를 조화시키는 작업.
  - **프로세스**: 기술 도구를 구축하고 배포하여 표준 엔티티 데이터를 확보.
  - 예: MDM 팀이 주소의 표준 형식을 정한 후 데이터 엔지니어와 함께 API를 구축하여 회사 부서 전반에 일관된 고객 레코드를 제공.

#### 데이터 모델링 및 설계
- **의의**: 비즈니스 분석 및 데이터 과학을 통해 데이터에서 인사이트를 얻으려면, 데이터는 사용 가능한 형태로 제공되어야 함.
  - 이를 위해 데이터를 변환하는 과정을 **데이터 모델링 및 설계**라고 함.

- **역할의 확장**: 데이터베이스 관리자와 ETL 개발자만의 역할이 아니며, 조직 전반에서 이루어질 수 있음.
  - 다양한 데이터 원천과 사용 사례로 인해 모델링이 더욱 어려워지고 있음.

- **도전과제**:
  - 엄격한 정규화 방식이 모든 데이터 유형에 적용되지 않음.
  - 클라우드 데이터 웨어하우스는 비정형 데이터도 처리할 수 있어야 함.
  - 데이터 처리 프레임워크는 플랫 정형 관계형 레코드에서 원시 비정형 텍스트에 이르는 다양한 데이터를 수집해야 함.

- **유연성 개발**:
  - 데이터 엔지니어는 다양한 데이터 원천과 사용 사례에 적합한 수준과 유형의 모델링을 적용해야 함.
  - 데이터 모델링 모범 사례를 이해하고, 데이터의 종류에 맞춰 효율적인 모델링을 적용할 수 있어야 함.


#### 데이터 모델링 및 설계
- **목적**: 비즈니스 분석과 데이터 과학을 통해 데이터에서 인사이트를 얻으려면, 데이터를 사용 가능한 형태로 제공해야 합니다. 이를 위해 데이터를 구조화하는 과정을 **데이터 모델링 및 설계**라고 합니다.

- **역할의 범위**: 전통적으로 데이터베이스 관리자와 ETL 개발자의 책임으로 간주되었지만, 데이터 모델링은 조직 전반에서 이루어져야 합니다.

- **과제**:
  - **새로운 데이터 원천과 사용 사례**로 인해 데이터 모델링이 복잡해지고 있습니다.
  - 엄격한 정규화 방식은 모든 데이터에 적합하지 않습니다.
  - 클라우드 데이터 웨어하우스는 방대한 양의 비정형 및 반정형 데이터를 수집, 처리합니다.
  - 스파크와 같은 데이터 처리 프레임워크는 단순한 정형 데이터부터 복잡한 비정형 데이터까지 처리합니다

- **유연성 개발**:
  - 데이터 엔지니어는 데이터 원천과 사용 사례에 적합한 모델링 방식을 선택해야 합니다.
  - 데이터 모델링의 모범 사례를 이해하고, 각 데이터 유형에 따라 적절한 수준과 형태의 모델링을 적용할 수 있어야 합니다.

#### 데이터 계보
- **정의**: 데이터 계보는 데이터를 처리한 시스템과 데이터가 의존하는 업스트림 데이터를 추적하여, 수명 주기 전체에서 데이터의 감사 추적을 기록하는 것을 말합니다.

- **목적 및 이점**:
  - 데이터가 이동하고 변환되는 과정에서 어떤 시스템이 영향을 미쳤는지 파악합니다.
  - 데이터에 포함된 구성 요소와 그 출처를 추적합니다.
  - 데이터 및 시스템의 오류를 추적하고 설명하며 디버깅에 도움을 줍니다.
  - 수명 주기 전반에 걸친 감사 추적을 제공해 규정 준수에도 도움이 됩니다.


#### 데이터 통합과 상호 운용성

- **정의**: 여러 도구와 프로세스 전반에 걸쳐 데이터를 통합하는 프로세스.

- **배경**:
  - 과거 단일 스택 접근 방식에서 다양한 도구가 데이터를 온디맨드로 처리하는 이기종 클라우드 환경으로 전환.
  - 이 변화는 데이터 엔지니어의 작업 범위를 확장.

- **특징**:
  - 데이터 통합이 맞춤형 데이터베이스 연결 대신 범용 API를 통해 이루어짐.
  - 데이터 처리보다는 파이썬 코드를 통한 데이터 시스템과의 간단한 통신.
  - 상호작용의 복잡성 감소 대신 시스템 수와 데이터 파이프라인의 복잡성 증가.

#### 데이터 수명 주기 관리
- **문제 인식**: 데이터 레이크의 등장으로 조직이 데이터 보관 및 폐기를 무시하기 시작했음. 그러나 데이터 엔지니어링 수명 주기의 마지막 단계에 더 많은 관심을 기울이게 하는 두 가지 변화가 있음.

- **두 가지 변화**:
  - **클라우드 스토리지 비용**: 클라우드 스토리지 사용 증가로 초기 자본 지출 대신 종량제 스토리지 비용 발생. 주요 클라우드 벤더는 저렴한 비용의 장기간 보존용 아카이브 스토리지 클래스를 제공함.
  - **데이터 보존법**: GDPR과 CCPA 같은 법률로 인해 데이터 엔지니어는 사용자의 '잊혀질 권리'를 존중하기 위해 데이터 파기를 관리해야 함.

- **조치 및 도구**:
  - 데이터 엔지니어는 현재 보유한 소비자 데이터를 파악하고, 요청 및 컴플라이언스 요건에 따라 데이터 파기 절차를 수행해야 함.
  - 클라우드 데이터 웨어하우스에서 **SQL**의 `WHERE` 절로 쉽게 데이터 삭제 가능.
  - **하이브 ACID** 및 **델타 레이크** 같은 도구를 사용해 규모에 맞는 데이터 삭제 트랜잭션을 쉽게 관리함.
  - 차세대 메타데이터 관리, 데이터 계보, 카탈로그 도구로 수명 주기의 마지막 단계를 간소화할 수 있음.

### 2.2.3 데이터옵스

**데이터옵스**는 애자일 방법론, 데브옵스, 통계적 공정 관리(SPC)의 모범 사례를 데이터 관리에 적용하는 방식임. 데브옵스가 소프트웨어 릴리즈와 품질을 개선하는 것처럼, 데이터옵스는 데이터 제품에 대해 같은 작업을 수행함.

**목표**:
- 신속한 혁신과 실험으로 고객에게 새로운 통찰력 제공
- 높은 데이터 품질과 낮은 오류율 달성
- 복잡한 인력, 기술, 환경 간 협업 촉진
- 명확한 측정, 모니터링 및 투명성 확보

**핵심 요소**:
- **자동화**: 반복적이고 수동적인 작업을 최소화해 효율을 높임.
- **모니터링 및 관찰 가능성**: 시스템 성능을 파악해 문제를 조기에 발견하고 대응함.
- **사고 대응**: 발생한 문제에 빠르게 대응할 수 있는 절차 마련.

**문화적 중요성**:
- 데이터옵스는 단순한 기술이 아니라 **문화적 습관**임.
- 데이터 엔지니어링 팀은 **협업, 지속적 학습, 빠른 반복 주기** 등의 문화적 습관을 정착시켜야 함.
- 이 습관이 있어야만 도구와 기술을 통해 최상의 결과를 얻을 수 있음.

**도입 전략**:
- 데이터 인프라가 없는 기업이라면 처음부터 데이터옵스를 도입할 수 있는 기회가 됨.
- 기존 시스템을 가진 기업은 모니터링 및 관찰 가능성부터 시작해 시스템 성능을 파악하고, 이후 자동화와 사고 대응 기능을 추가함.
- 기존 데이터옵스 팀과 협력해 기업의 데이터 성숙도에 맞춰 데이터 엔지니어링 수명 주기를 계산할 수 있음.


#### 자동화

**목적**: 데이터옵스에서 자동화를 통해 프로세스의 **신뢰성과 일관성**을 보장함. 이를 통해 데이터 엔지니어는 새로운 기능이나 계산을 빠르게 기존 워크플로에 구현할 수 있음.

**데브옵스와의 유사성**:
- 자동화는 데브옵스의 변경 관리, 지속적 통합 및 배포 등과 유사한 프레임워크 및 워크플로를 가짐.
- 데이터옵스 자동화는 데이터 품질, 데이터 모델 변화, 메타데이터 무결성 등을 확인해 기술과 시스템의 신뢰성을 유지함.

**원칙**:
- 데이터옵스의 원칙 중 하나인 **변화 수용**은 목표 지향적 변화임.
- 자동화 단계마다 운영 개선의 기회가 있음.

**고도화 가능성**:
- 메타데이터 역량을 기반으로 한 차세대 조정 프레임워크 도입
- 데이터 계보를 기반으로 DAG를 자동으로 구축하는 프레임워크 개발

**핵심**: 엔지니어는 자동화를 통해 워크로드를 줄이고, 비즈니스에 제공하는 가치를 높이는 방향으로 지속적인 개선을 추구해야 함.

#### 관찰 가능성과 모니터링

- **필요성**: 불량 데이터의 사례는 수없이 많음. 잘못된 데이터로 인한 결정 오류는 시간이 지나서야 발견되며, 이는 때로는 비즈니스에 치명적임. 데이터와 데이터 생성 시스템을 감시하지 않으면 데이터 문제에 직면할 수 있음.

- **중요성**: 관찰 가능성, 모니터링, 로깅, 경고, 추적은 데이터 엔지니어링 수명 주기에서 발생하는 문제에 대처하는 데 필수적임. SPC(통계적 공정 관리)를 통합해 이벤트의 문제 여부와 대응 필요성을 파악하는 것이 좋음.

- **DODD 방법론**:
  - 페트렐라의 DODD(Data Observability-Driven Development) 방법론은 소프트웨어의 TDD(Test-Driven Development)와 유사함.
  - DODD의 목적은 데이터와 데이터 애플리케이션에 대한 가시성을 확보하고 변경 사항을 수집해 모든 단계에서 문제를 식별함으로써, 데이터 문제를 해결하거나 예방하는 데 있음.
  - 데이터 엔지니어링 수명 주기에서 **관찰 가능성**을 최우선 고려 사항으로 삼음.

#### 사고 대응

- **의미**: 사고 대응은 자동화 및 관찰 가능성 기능을 활용해 데이터 엔지니어링 수명 주기에 발생하는 문제의 근본 원인을 신속히 파악하고 가능한 빠르게 해결하는 것을 의미함.

- **예방**:
  - 데이터 엔지니어는 문제를 기업이 보고하기 전에 미리 발견해야 함.
  - 이해관계자나 최종 사용자가 문제를 직접 발견하지 않도록 하는 것이 중요함. 이러한 상황은 그들이 좋아하지 않음.

- **신뢰**:
  - 신뢰는 쌓는 데 시간이 걸리지만, 몇 분 만에 무너질 수 있음.
  - 사고 대응은 사고 전 예방뿐만 아니라, 사고 발생 후에 대처하는 것도 중요함.

#### 데이터 옵스 요약

데이터 엔지니어는 데이터 옵스 작업에 높은 우선순위를 두어야 함. 이를 통해 다음과 같은 장기적 성과를 얻을 수 있음:

- **제품의 신속한 제공**
- **데이터의 신뢰성 및 정확성 향상**
- **비즈니스의 전반적인 가치 향상**


### 2.2.5 오케스트레이션

오케스트레이션은 다양한 작업이 정해진 순서대로 빠르고 효율적으로 실행되도록 조정하는 프로세스임. 예를 들어, 에어플로우 같은 오케스트레이션 도구를 스케줄러로 부르기도 하지만 이는 정확하지 않음. 오케스트레이션 엔진은 유향 비순환 그래프(DAG) 형태로 작업 종속성을 구축함.

- **기능**:
  - 관리하는 작업을 모니터링하고, DAG 종속성 완료 시 새로운 작업을 시작함.
  - 특정 조건이 범위를 벗어나면 오류 조건을 설정하고 경고를 보냄.
  - 작업 기록, 시각화, 경고 기능을 제공함.

- **고급 기능**:
  - 백필(Backfill): 새로운 DAG나 개별 작업이 DAG에 추가될 때, 과거 작업을 채울 수 있음.

오케스트레이션 시스템은 오랫동안 데이터 처리의 핵심 기능이었지만, 쉽게 접근할 수 있는 건 아니었음. 에어플로우는 오픈 소스로 시작해 널리 채택되었고, 파이썬으로 작성되어 다양한 사용 사례로 확장 가능함. 데이터 처리에 대한 접근성이 높아지면서 여러 시스템 간 복잡한 흐름을 조정하는 데에 대한 관심이 증가했고, 에어플로우는 이러한 니즈를 충족시킴.

### 2.2.6 소프트웨어 엔지니어링

클라우드 데이터 웨어하우스는 SQL 시맨틱을 통한 강력한 변환을 지원함. 스파크 같은 도구는 저수준 코딩을 데이터프레임으로 추상화하며 사용자 친화적으로 발전함. 그럼에도 불구하고 소프트웨어 엔지니어링은 여전히 데이터 엔지니어링에 필수적임. 데이터 엔지니어링 수명 주기에 적용되는 주요 소프트웨어 엔지니어링 영역을 살펴보겠음.

#### 코어 데이터 처리 코드
- 추상화가 진전되었지만, 코어 데이터 처리 코드는 여전히 수명 주기 전체에서 작성되어야 함.
- 데이터 엔지니어는 수집, 변환, 데이터 서빙에서 스파크, SQL, 빔 등의 프레임워크를 능숙하게 활용할 수 있어야 함.
- 단위, 회귀, 통합, 엔드투엔드, 스모크 테스트 등의 코드 테스트 방법론을 이해해야 함.

#### 오픈 소스 프레임워크 개발
- 빅데이터 시대에는 하둡 생태계 내 데이터 처리 프레임워크가 크게 늘어남.
- 이러한 도구들은 데이터 엔지니어링 수명 주기 중 일부에 초점을 맞춤.
- 데이터 엔지니어링 도구의 발전이 멈추지는 않았지만, 추상화에 초점을 두기 시작함.

- **예시**: 에어플로우는 2020년대 초반 오케스트레이션 분야를 주도했지만, 그 한계를 보완하려는 오픈 소스 경쟁 업체들이 등장함. 이들은 더 나은 메타데이터 처리와 이식성 및 종속성 관리를 제공함.

데이터 엔지니어는 자체 도구를 개발하기 전에 공개적으로 사용 가능한 도구를 조사하는 것이 좋음. 총 소유 비용(TCO)과 기술 비용을 고려해야 하며, 기존 오픈 소스 프로젝트가 문제를 해결할 수 있다면 처음부터 개발하는 것보다 협업하는 편이 나을 수 있음.

#### 스트리밍
스트리밍 데이터 처리는 배치 처리보다 복잡하며 도구와 패러다임이 아직 덜 성숙함. 스트리밍 데이터가 수명 주기의 모든 단계에 퍼지면서 데이터 엔지니어는 복잡한 소프트웨어 엔지니어링 문제에 직면함. 배치 처리에서 간단한 조인도 실시간 처리에서는 복잡해짐. 또한 다양한 윈도잉 방법을 적용하는 코드도 작성해야 함. 실시간 시스템에서 추적 통계 등의 지표를 계산할 수 있고, 여러 프레임워크로 보고 및 실시간 처리를 지원하는 스트림 분석도 가능함.

#### 코드형 인프라
코드형 인프라(IaC)는 인프라 구성 및 관리를 소프트웨어 엔지니어링 관행에 적용함. 빅데이터 시대의 인프라 부담이 관리형 빅데이터 시스템이나 클라우드 데이터 웨어하우스로 옮겨감에 따라 줄어듦. 프레임워크를 통해 자동 배포하며, 버전 제어와 반복성도 실현할 수 있음.

#### 코드형 파이프라인
코드형 파이프라인은 오케스트레이션 시스템의 핵심 개념임. 데이터 엔지니어는 코드를 사용해 작업과 종속성을 선언함.

#### 범용 문제 해결
고급 도구를 채택해도 데이터 엔지니어는 수명 주기 전반에 걸쳐 도구의 경계를 벗어나 문제를 해결해야 함. API 이해, 데이터 수집 및 변환, 예외 처리 등 다양한 소프트웨어 엔지니어링 능력을 갖춰야 함.

## 2.3 결론
데이터 엔지니어링 수명 주기는 데이터 생성, 저장, 수집, 변환, 서빙의 단계로 나눌 수 있음.

주요 요소에는 보안, 데이터 관리, 데이터 옵스, 데이터 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링이 포함됨.

데이터 엔지니어는 수명 주기 전반에서 ROI를 최적화하고, 비용 및 재무 위험을 줄이며 데이터 가치와 효용을 최대화하는 목표를 가짐.

# 3. 우수한 데이터 아키텍처 설계

3장에서는 먼저 데이터 아키텍처를 정의하고 주요 구성 요소와 고려 사항을 설명함. 이어서 배치 패턴, 스트리밍 패턴, 그리고 배치와 스트리밍의 통합 패턴을 다루며, 확장성, 가용성, 신뢰성을 제공하는 클라우드 기능의 중요성을 강조함.

## 3.1 데이터 아키텍처란?

데이터 아키텍처의 정의를 이해하기 위해, 해당 용어가 속한 컨텍스트를 파악하는 것이 중요함.

### 3.1.1 엔터프라이즈 아키텍처 정의

엔터프라이즈 아키텍처(EA)는 비즈니스, 기술, 애플리케이션 및 데이터 등 다양한 하위 집합을 포함함.

**TOGAF**: TOGAF(The Open Group Architecture Framework)는 가장 널리 사용되는 아키텍처 프레임워크로, 엔터프라이즈 아키텍처는 기업 내 다양한 시스템과 기능 그룹을 아우름. 

**Gartner**: Gartner는 기업 동향 관련 리서치 및 자문을 제공하며, 엔터프라이즈 아키텍처를 "기업이 파괴적인 힘에 능동적으로 대응할 수 있도록 도와주는 분야"로 정의함. 이를 통해 비즈니스 및 IT 리더는 바람직한 비즈니스 결과를 위해 정책 및 프로젝트를 조정할 수 있음.

**EABOK**: EABOK는 미국 마이토 코퍼레이션에서 작성한 엔터프라이즈 아키텍처 참조 자료로, 엔터프라이즈 아키텍처를 "기업의 전략, 운영 및 기술을 조정하는 조직 모델"로 정의함.


**우리의 정의:** 엔터프라이즈 아키텍처는 조직 변화를 지원하기 위한 유연하고 가역적인 시스템 설계임. 이 설계가 중요한 이유는 다음과 같음:

1. **변화에 적응:** 세상은 지속적으로 변하며 미래를 예측하기 어려움. 유연하고 가역적인 의사결정은 변화와 새로운 정보에 맞춰 프로세스를 조정할 수 있도록 해줌.

2. **경직성 극복:** 조직이 성장하면 경직화되는 경향이 있음. 가역적인 의사결정은 경직화에 따른 위험을 줄여 유연성을 유지하는 데 도움이 됨.

**영감 출처:** 마이크 리처즈와 닐 포드의 *'소프트웨어 아키텍처 101'*에서 트레이드오프의 중요성을 강조함. 소프트웨어와 데이터의 유동적인 특성으로 엔지니어는 물리적 제약에서 벗어났다고 느끼지만, 실제로는 여전히 물리적 및 비물리적 한계를 극복해야 함.

**핵심 강조점:** 유연성과 트레이드오프의 균형을 유지하는 것이 중요함. 변화하는 환경에 적응하려면 지속적으로 균형을 유지하고 시스템을 재평가해야 함.


### 3.1.2 데이터 아키텍처 정의

데이터 아키텍처는 엔터프라이즈 아키텍처의 하위 집합으로, 전략적 변경 관리와 트레이드오프 평가 등의 속성을 상속함.

#### TOGAF의 정의
- 주요 데이터 유형
- 논리적 데이터 자산
- 물리적 데이터 자산
- 데이터 관리 자원의 구조와 상호작용

#### DAMA의 정의
- 기업의 데이터 요구 사항 파악
- 마스터 청사진 설계 및 유지 관리
- 데이터 통합 안내
- 데이터 자산 제어
- 데이터 투자를 비즈니스에 맞게 조정

#### 우리의 정의
- **목적**: 기업의 진화하는 데이터 요구 사항을 지원하는 시스템 설계
- **방법**: 트레이드오프에 대한 신중한 평가를 통해 유연하고 되돌릴 수 있는 결정 내림

#### 데이터 아키텍처의 적용

#### 운영 아키텍처
- **요건**: 인력, 프로세스 및 기술과 관련된 기능 요건
- **질문**:
  - 데이터는 어떤 비즈니스 프로세스를 지원하는가?
  - 조직은 데이터 품질을 어떻게 관리하는가?
  - 데이터 수집부터 쿼리 가능 시점까지의 지연 시간 요구 사항은?

#### 기술 아키텍처
- **설명**: 데이터를 수집, 저장, 변환 및 제공하는 방법
- **예시**: 시간당 10 테라바이트의 데이터를 원천 데이터베이스에서 데이터 레이크로 옮기는 방법

#### 요약
- 데이터 아키텍처는 엔터프라이즈 아키텍처의 일부분으로, 유연하고 가역적인 시스템 설계를 목표로 함.
- TOGAF와 DAMA는 데이터 아키텍처의 구성 요소와 역할을 정의함.
- 데이터 엔지니어링 수명 주기를 통해 운영 및 기술 아키텍처를 설계함.

### 3.2.1 원칙 1: 공통 컴포넌트를 현명하게 선택하라

#### 주요 업무
- 조직 전체에서 널리 쓸 수 있는 공통 컴포넌트와 관행을 선택
- 팀 협업을 촉진하고 사일로를 허무는 역할 수행
- 팀 내에서 또는 팀 간의 공유된 지식 및 기술과 함께 민첩성을 실현

#### 공통 컴포넌트의 예
- 객체 스토리지
- 버전 제어 시스템
- 관찰 가능성 모니터링 및 오케스트레이션 시스템
- 처리 엔진

#### 공통 컴포넌트의 필요성
- 적절한 사용 사례를 통해 누구나 접근 가능
- 처음부터 다시 개발하는 시간을 절약
- 강력한 권한과 보안을 지원하여 팀 간 자산을 공유하면서 부정 접근 방지

#### 선택 시 고려 사항
- 데이터 엔지니어링 수명 주기와 팀 전반에 걸친 요구사항에 초점
- 개별적으로 활용하면서 상호 운용과 협업 촉진
- 균형 잡힌 작업이 필요

### 3.2.2 원칙 2: 장애에 대비하라

#### 중요성
- 최신 하드웨어는 견고하지만, 시간이 지나면 장애가 발생할 수 있음
- 견고한 데이터 시스템을 구축하려면 설계 시 장애를 고려해야 함

#### 주요 개념

**가용성**
- IT 서비스 또는 컴포넌트가 작동 가능한 상태에 있는 시간의 비율

**신뢰성**
- 지정된 간격 동안 의도된 기능을 수행할 때 시스템이 정의된 표준을 충족할 확률

**복구 시간 목표 (RTO)**
- 서비스 또는 시스템 장애의 최대 허용 시간
- 운영 중단이 비즈니스에 미치는 영향을 고려하여 설정됨
- 예: 내부 보고서 시스템의 RTO는 하루 정도일 수 있지만, 온라인 소매업자는 5분 중단도 큰 영향을 미침

**복구 시점 목표 (RPO)**
- 복구 후 허용 가능한 상태
- 허용 가능한 최대 데이터 손실을 나타냄
- 데이터 시스템에서는 운영 중단 시 데이터 손실이 발생할 수 있음

#### 설계 시 고려 사항
- 허용 가능한 신뢰성
- 가용성
- 복구 시간 목표 (RTO)
- 복구 시점 목표 (RPO)


### 3.2.4 원칙 4: 아키텍처는 리더십이다

#### 역할과 책임
- 데이터 아키텍트는 기술적으로 유능해야 하지만, 대부분의 개별 기여자 작업을 위임해야 함
- 기술 역량과 리더십 기술을 겸비한 데이터 아키텍트는 매우 가치 있음

#### 이상적인 데이터 아키텍트의 특징
- 데이터 엔지니어와 같은 기술 보유
- 매일 데이터 엔지니어링을 연습하지 않음
- 현직 데이터 엔지니어를 지도하고, 조직과 협의하여 기술 선택 및 교육
- 리더십을 통해 지식을 전파하고 모범 사례를 교육
- 회사의 엔지니어링 자원을 통합하여 기술과 비즈니스 목표를 추구


### 3.2.5 원칙 5: 항상 아키텍처에 충실하라

#### 데이터 아키텍트의 역할
- 비즈니스와 기술 변화에 대응하여 새로운 설계 개발
- 기본 아키텍처에 대한 깊은 지식 개발
- 목표 아키텍처 개발
- 아키텍처 변경의 우선순위와 순서를 결정하는 시퀀싱 계획 수립

#### 현대 아키텍처의 특징
- 협력적이고 민첩한 방식 필요
- 시간에 따라 변화하는 목표와 시퀀싱 계획 유지
- 목표와 계획은 비즈니스와 기술의 변화에 따라 조정
- 시퀀싱 계획은 제품의 즉각적인 전달에 대한 우선순위 결정

### 3.2.6 원칙 6: 느슨하게 결합된 시스템을 구축하라

#### 느슨한 결합의 중요성
- 팀이 다른 팀에 의존하지 않고 시스템을 테스트, 배포, 변경할 수 있도록 설계
- 시스템과 팀 모두 느슨하게 결합되어야 함

#### 베이조스 API 선언문 (2002)
1. 모든 팀은 서비스 인터페이스를 통해 데이터와 기능을 공개해야 함
2. 각 팀은 이러한 인터페이스로 소통해야 함
3. 다른 형태의 프로세스 간 통신은 허용되지 않음
4. 어떤 기술을 사용하는지는 중요하지 않음
5. 모든 서비스 인터페이스는 외부화할 수 있도록 설계되어야 함

#### 느슨하게 결합된 시스템의 속성
1. 시스템은 많은 작은 컴포넌트로 나뉨
2. 추상화 계층(메시징 버스, API 등)을 통해 다른 서비스와 상호작용
3. 내부 변경은 다른 부분에 영향을 미치지 않음
4. 시스템은 개별적으로 갱신되고 발전함

#### 기술적 특징과 조직적 특징
1. 많은 소규모 팀이 복잡한 시스템을 설계하고 유지보수
2. 팀은 API와 메시지 스키마를 통해 추상적인 세부 사항을 공개
3. 팀은 독립적으로 컴포넌트를 발전시키고 갱신
4. 최소한의 다운타임으로 컴포넌트를 배포할 수 있음

#### 결론
- 기술과 인간 시스템을 느슨하게 결합하면 데이터 엔지니어링 팀이 효율적으로 협업 가능
- 원칙 7을 직접적으로 촉진

### 3.2.7 원칙 7: 되돌릴 수 있는 의사결정을 하라
- 데이터 환경은 빠르게 변화하며, 현재의 인기 있는 기술이 금방 과거의 유물이 될 수 있음
- 아키텍처를 단순하고 민첩하게 유지하기 위해 되돌릴 수 있는 의사결정을 목표로 함
- 소프트웨어 설계에서 돌이킬 수 없는 부분들을 제거하는 방법을 찾아 아키텍처를 설계
- 기술의 분리, 모듈화 등을 통해 현재의 적합한 솔루션을 선택하고, 환경의 진화에 따라 업그레이드나 더 나은 방법을 채택할 준비를 함

### 3.2.8 원칙 8: 보안 우선순위를 지정하라
- 데이터 엔지니어는 자신이 구축하고 유지 관리하는 시스템의 보안을 책임져야 함
- 제로 트러스트 보안과 책임공유 보안 모델에 초점을 맞춤
- **강화된 경계 보안 모델과 제로 트러스트 보안 모델**
  - 전통적인 경계 보안 모델은 내부와 외부를 구분하는 네트워크 경계 설정에 의존
  - 제로 트러스트 보안 모델은 내부자 공격과 외부 위협에 대비해 모든 접근을 검증

- **공동 책임 모델**
  - 클라우드 제공 업체는 서비스를 보호하고, 사용자는 애플리케이션 및 데이터 보안 모델을 설계하고 구현

- **보안 엔지니어로서의 데이터 엔지니어**
  - 핀옵스(FinOps)의 정의
    - 클라우드 재무 관리 분야이자 문화적 관행으로, 엔지니어링, 재무, 기술, 비즈니스 팀이 협업해 조직의 비즈니스 가치를 극대화함
  - 클라우드 시대의 종량제 방식과 비용 효율성을 고려해 스케일업과 스케일다운을 통해 비용을 관리
  - 클라우드 시스템의 비용 구조를 이해하고, 비용 효율성과 성능을 고려해 작업 수행

- **핀옵스의 운영 모니터링**
  - 지속적으로 지출을 모니터링하고, 데이터 접근 지출을 관리
  - 핀옵스 재단을 통해 공식화된 관행을 학습하고 적용

## 3.3 주요 아키텍처 개념
데이터 동향이 빠르게 변화하는 가운데, 아키텍처의 주요 목표는 데이터를 유용한 결과물로 변환하는 것임을 잊지 말아야 한다.

### 3.3.1 도메인과 서비스
- **도메인**: 지식, 영향력, 활동의 영역. 소프트웨어에서 실제 설계의 주제 영역.
- **서비스**: 특정 작업을 달성하는 기능 집합. 여러 서비스가 하나의 도메인에 포함될 수 있으며, 다른 도메인 간에 서비스를 공유할 수도 있음.

- 도메인을 구성할 때 실제 세계에서 도메인이 무엇을 나타내는지 고려.
- 도메인 내에서 해야 할 작업과 서비스를 결정하기 위해 사용자와 이해관계자와의 대화가 중요.
- 진공 상태에서 설계하는 전형적인 함정을 피하도록 노력해야 함.

### 3.3.2 분산 시스템: 확장성과 장애 대비 설계
데이터 시스템에서 중요한 네 가지 특징:
1. **확장성**: 시스템 자원을 늘려 성능을 개선하고 수요를 처리할 수 있음.
2. **탄력성**: 워크로드에 따라 자동으로 스케일 업/다운하여 비용을 절감하고 성능을 보장.
3. **가용성**: 시스템이 작동 가능한 시간의 비율.
4. **신뢰성**: 시스템이 의도된 기능을 수행할 확률.

- 시스템이 저장된 시간 동안 성능 요건을 충족하지 못하면 가용성이 저하됨.
- 동적 확장은 엔지니어의 개입 없이 성능을 보장, 탄력성은 신뢰성을 향상시킴.

#### 확장 방법
- **수직 확장**: 단일 머신의 자원을 늘림. 그러나 자원의 한계가 존재.
- **수평 확장**: 더 많은 머신을 추가하여 부하를 분산. 높은 가용성과 신뢰성을 제공.
  - 일반적인 수평 확장 시스템에는 리더 노드와 워커 노드가 있음.
  - 리더 노드는 작업을 워커 노드에 분산, 결과를 리더 노드로 반환.
  - 리더 노드가 중단되면 다른 서버가 역할을 이어받아 복구.

- 분산 시스템의 세부 관리는 추상화되어 있어 높은 수준의 아키텍처에 집중 가능.

마틴 클레프만의 [데이터 중심 애플리케이션 설계(위키북스, 2018)]는 이러한 내용을 학습하기에 좋은 자료임.

### 3.3.3 강한 결합 vs 느슨한 결합: 계층, 모놀리스, 마이크로서비스

데이터 아키텍처 설계 시, 다양한 도메인 서비스 및 자원의 상호 의존성을 고려해야 한다.

- **강한 결합**: 
  - 극도로 중앙 집중화된 종속성과 워크플로를 특징으로 함.
  - 도메인과 서비스의 모든 부분이 다른 도메인과 서비스에 필수적으로 의존.

- **느슨한 결합**:
  - 분산된 도메인과 서비스가 온전히 의존하지 않음.
  - 분산된 팀에서 데이터를 사용할 수 없는 시스템을 구축할 수 있음.
  - 각각의 도메인과 서비스를 공유하는 팀에게 공통의 표준, 소유권, 책임을 부여해야 함.

우수한 데이터 아키텍처를 설계하려면 도메인과 서비스의 강한 결합과 느슨한 결합 사이에서 적절한 트레이드오프를 찾아야 한다.

#### 아키텍처 계층
아키텍처는 데이터, 애플리케이션, 비즈니스 로직, 프레젠테이션 등의 계층으로 나뉜다. 이러한 계층을 분리하는 방법을 이해하는 것이 중요하다.

##### 단일 계층 아키텍처
- 데이터베이스와 애플리케이션이 밀접하게 연결되어 단일 서버에 상주.
- 강한 결합의 본질은 서버, 데이터베이스, 애플리케이션 중 하나에 장애가 발생하면 전체 아키텍처에 영향을 미침.
- 단일 계층 아키텍처는 프로토타이핑과 개발에는 유용하나, 운영 환경에서는 권장되지 않음.

##### 다중 계층 아키텍처
- 강하게 결합된 단일 계층 아키텍처의 문제점을 데이터, 애플리케이션, 비즈니스 로직, 프레젠테이션 등의 개별 계층으로 분리하여 해결.
- 계층들은 상향식이고 계층적 구조로, 하위 계층은 상위 계층에 의존하지 않지만, 상위 계층은 하위 계층에 의존.

**3계층 아키텍처**:
- 데이터 계층, 애플리케이션 로직 계층, 프레젠테이션 계층으로 구성.
- 각 계층은 다른 계층과 격리되어 있어 리스크를 분리 가능.
- 각 계층에서 원하는 모든 기술을 자유롭게 사용할 수 있음.

데이터 엔지니어는 계층을 사용해 아키텍처와 종속성을 평가해야 한다. 단순하게 시작하되, 아키텍처가 더 복잡해지면 추가 계층으로 진화시켜 나가야 한다.

##### 분산 시스템과 자원 공유
- 분산 시스템을 다룰 때는 계층을 분리하고 계층 내 자원을 공유하는 방식을 고려해야 함.
- 비공유 아키텍처: 단일 노드가 요청을 처리하며, 노드 간 자원을 공유하지 않음. 자원은 노드에 격리됨.
- 공유 디스크 아키텍처: 노드 간 디스크와 메모리를 공유하며, 보통 노드 장애 시 공유 자원을 필요로 할 때 사용.
- 분산 시스템에서는 데이터 엔지니어링 수명 주기 전반에 걸쳐 다양한 기술을 지원할 수 있음.

#### 모놀리스
- 모놀리스는 가능한 많은 것을 한 지붕 아래 포함하는 것이다.
- 모놀리스 내 결합 방식:
  - **기술 결합**: 아키텍처 계층 간의 결합.
  - **도메인 결합**: 도메인 간의 결합.
- 강한 결합은 컴포넌트의 모듈화 부족을 의미하며, 컴포넌트 재사용이 어렵다.
- 컴포넌트 개선 시 다른 영역에 알려지지 않은 결과를 초래할 수 있다.

#### 마이크로서비스 아키텍처
- 개별적이고 분산된 느슨하게 결합된 서비스로 구성된다.
- 각 서비스는 특정 기능을 가지며 다른 서비스와 분리되어 있다.
- 한 서비스가 중단되더라도 다른 서비스의 기능에는 영향을 주지 않는다.

##### 모놀리스를 여러 마이크로서비스로 전환
- 모놀리스의 복잡성과 서비스 추출 노력에 따라 전환 방식이 달라진다.
- 모놀리스 분리가 어렵다면 마이크로서비스 친화적인 방식으로 병렬 아키텍처를 구축해야 한다.
- 전체적인 리팩터링보다는 서비스 분리를 제안한다.
- 더 자세한 내용은 닐 포드의 [소프트웨어 아키텍처 the hard part(한빛미디어, 2022)]를 참고하자.

#### 데이터 아키텍처에 관한 고려 사항
- 중앙 데이터 웨어하우스는 본질적으로 모놀리식하다.
- 마이크로서비스 전환은 도메인별 데이터 파이프라인과 워크플로를 분리하는 것이다.
- 데이터 기술의 상태와 한계를 인식하면서 모듈화와 느슨한 결합을 실용적으로 사용할 것을 권장한다.
- 아키텍처 컴포넌트를 수직적으로 여러 관심 계층으로 나눈다.
- 다중계층 아키텍처는 기술적 문제를 해결하지만 공유 도메인의 복잡성을 해결하지 못한다.
- **중앙 집중화 접근 방식**: 단일 팀이 모든 도메인 데이터를 수집해 조직 전체에서 사용하도록 조정.
- **데이터 메시 접근 방식**: 각 소프트웨어 팀이 조직 전체에서 사용할 데이터를 준비할 책임을 진다.

모놀리스가 반드시 나쁜 것은 아니며, 특정 조건에서는 모놀리스로 시작하는 것이 합리적일 수 있다.

### 3.3.4 사용자 접근: 싱글 vs 멀티테넌트
데이터 엔지니어는 시스템을 여러 팀, 조직, 고객과 공유할지를 결정해야 한다. 클라우드 서비스는 기본적으로 멀티테넌트이지만, 방식은 다양하다.

- **멀티테넌시의 고려사항**:
  - **성능**: 모든 테넌트에 대해 일관된 성능을 지원하는가? 한 테넌트의 높은 사용량이 다른 테넌트의 성능에 영향을 미치는가?
  - **보안**: 테넌트 간 데이터를 적절히 분리해야 한다. 벤더 또는 프로젝트 설명서를 통해 적절한 전략과 리스크를 파악하자.

### 3.3.5 이벤트 기반 아키텍처
이벤트 기반 워크플로는 데이터 엔지니어링 수명 주기의 다양한 부분에서 이벤트를 생성, 갱신하고 비동기적으로 이동하는 기능을 포함한다. 이벤트는 생산자, 이벤트 라우터, 소비자 간에 강하게 결합된 종속성 없이 생성되고 라우팅된다.

- **장점**:
  - 이벤트 상태가 여러 서비스에 분산됨.
  - 서비스 오프라인 또는 노드 장애 시 유용.
  - 여러 소비자 또는 서비스가 동일한 이벤트 접근 가능.
  - 느슨한 결합된 서비스에 적합.

### 3.3.6 브라운필드 vs 그린필드 프로젝트
프로젝트는 브라운필드와 그린필드로 나뉜다.

#### 브라운필드 프로젝트
기존 아키텍처를 리팩터링 및 재구성하며, 현재와 과거의 선택에 따른 제약을 받는다. 레거시 아키텍처에 대한 철저한 이해와 신/구 기술의 상호작용이 필요하다.

- **변경 관리**:
  - **스트랭글러 패턴**: 새로운 시스템이 레거시 아키텍처의 컴포넌트를 점진적으로 대체. 종속 시스템에 미치는 영향을 평가하며 유연하고 되돌릴 수 있는 결정 가능.

#### 그린필드 프로젝트
이전 아키텍처의 역사나 레거시에 얽매이지 않고 새롭게 시작.

- **주의 사항**:
  - 최신 기술 유행을 무작정 따르는 것보다 프로젝트의 궁극적인 목표를 우선시.
  - 작업 요건을 우선시하고, 이력서 주도 개발 유혹을 피하자.

항상 우수한 데이터 아키텍처 원칙에 집중하고, 트레이드오프를 평가하며, 유연하고 되돌릴 수 있는 결정을 내리고 긍정적인 ROI를 실현하도록 노력하자.

## 3.4 데이터 아키텍처의 사례 및 유형

### 3.4.1 데이터 웨어하우스
보고 및 분석에 사용되는 중앙 데이터 허브로 가장 오래되고 잘 확립된 데이터 아키텍처 중 하나다. 일반적으로 분석 활용 사례에 맞게 고도로 포맷되고 구조화되어 있다.

확장성이 뛰어난 종량제 모델 덕분에 소규모 기업도 클라우드 데이터 웨어하우스에 접근할 수 있게 되었다. 서드 파티 제공 업체가 데이터 웨어하우스 인프라를 관리하기 때문에 기업은 데이터의 복잡성이 증가하더라도 적은 인력으로 훨씬 더 많은 작업을 수행할 수 있다.

#### 조직 데이터 웨어하우스 아키텍처
특정 비즈니스팀의 구조 및 프로세스와 관련된 데이터를 구성한다. 운영 데이터베이스(온라인 트랜잭션 처리(OLTP))에서 온라인 분석 처리(OLAP)를 분리한다. 이러한 분리는 비즈니스가 성장함에 따라 매우 중요하다. 데이터를 별도의 물리적 시스템으로 옮기면 운영 시스템의 부하가 줄어들고 분석 성능이 향상된다.

- **중앙 집중화 및 구성**: 전통적으로 데이터 웨어하우스는 ETL을 사용해 애플리케이션 시스템에서 데이터를 가져온다. 
  - **추출 단계**: 원천 시스템에서 데이터를 가져옴.
  - **변환 단계**: 데이터를 정리하고 표준화해 모델링된 형태로 변환.
  - **적재 단계**: 데이터가 데이터 웨어하우스 대상 데이터베이스 시스템에 적재됨.

데이터는 특정 라인이나 비즈니스 및 부서의 분석 요구를 충족하기 위해 여러 데이터 마트에 적재된다.

#### 기술 데이터 웨어하우스 아키텍처
MPP와 같은 데이터 웨어하우스의 기술적 본질을 반영한다. MPP는 대량의 데이터를 병렬 처리하여 고성능 집계 및 통계 분석을 가능하게 한다.

- **MPP 시스템**: 기본적으로 관계형 데이터베이스와 동일한 SQL 시멘틱을 지원하지만, 대량의 데이터를 병렬 처리하여 고성능을 발휘한다. 이는 데이터 및 보고 업무에 필요한 대기업에서 필수적이다.

#### 클라우드 데이터 웨어하우스
온프레미스 데이터 웨어하우스 아키텍처의 상당한 발전을 의미하며 조직 아키텍처에 큰 변화를 가져왔다.

- **아마존 레드시프트**: 클라우드 데이터 웨어하우스 혁명을 이끌었다. 기업은 레드시프트 클러스터를 온디맨드로 생성하여 데이터 및 분석 수요에 따라 확장할 수 있다. 필요에 따라 새로운 클러스터를 생성해 특정 워크로드를 처리하고 더 이상 필요하지 않은 클러스터를 신속하게 해제할 수도 있다.
  
- **구글 빅쿼리, 스노우플레이크**: 컴퓨팅과 스토리지를 분리하는 아이디어를 대중화했다. 데이터는 객체 스토리지에 저장되어 사실상 무제한 스토리지를 사용할 수 있다. 이를 통해 사용자는 컴퓨팅 파워를 필요에 따라 조정할 수 있으며, 장기적인 비용 없이 애드혹 빅데이터 기능을 제공할 수 있다.

클라우드 데이터 웨어하우스는 MPP 시스템의 기능을 확장해 많은 빅데이터 사용 사례를 포괄한다. 단일 쿼리로 페타바이트 단위의 데이터를 쉽게 처리할 수 있다. 일반적으로 행당 수십 메가바이트의 텍스트 데이터 또는 매우 풍부하고 복잡한 JSON 문서를 저장할 수 있는 데이터 구조를 지원한다.

### 3.4.2 데이터 마트
단일 조직이나 부서 또는 비즈니스 라인에 초점을 맞춰 분석 및 보고서를 제공하도록 설계된 웨어하우스의 한층 더 정교한 집합이다. 각 부서에는 필요에 따라 고유한 데이터 마트가 있으며, 이는 더 광범위한 조직 전체에 비즈니스 서비스를 제공하는 전체 데이터 웨어하우스와는 대조적이다.

데이터 마트가 필요한 이유:
- **분석과 보고서 개발자가 데이터에 더 쉽게 접근할 수 있도록 함.**
- **데이터 마트는 초기 ETL 또는 ELT 파이프라인이 제공하는 것보다 더 많은 변환 단계를 제공함.** 
  - 따라서 보고서 또는 분석 활동에 복잡한 데이터 조인 및 집계가 필요한 경우 특히 원시 데이터가 큰 경우 성능이 크게 향상될 수 있다.

### 3.4.3 데이터 레이크
데이터에 엄격한 구조적 제한을 가하지 않고 정형 데이터와 비정형 데이터를 모두 중앙 위치에 저장하는 방식이다. 데이터 레이크 1.0은 HDFS에서 시작되었으며, 저렴한 스토리지 비용과 무제한 용량을 갖춘 클라우드 기본 객체 스토리지로 옮겨왔다.

데이터 레이크의 장점:
- **모든 크기와 유형의 방대한 데이터를 저장할 수 있음.**
- **데이터를 처리하고 변환해야 할 때 클러스터를 온디맨드로 스핀업하여 무제한에 가까운 컴퓨팅 성능을 이용할 수 있음.**
- **맵리듀스, 스파크, 프레스토, 하이브 등 원하는 데이터 처리 기술을 선택해 작업 수행 가능.**

데이터 레이크의 단점:
- 데이터 스키마 관리, 데이터 카탈로그 작성 및 검색 도구가 거의 없어 관리가 어려움.
- 빅데이터 처리 복잡성으로 인해 엔지니어링 팀이 필요하고, 이로 인해 비용이 증가함.

### 3.4.4 융합, 차세대 데이터 레이크, 데이터 플랫폼
데이터 레이크 하우스는 데이터 웨어하우스에서 볼 수 있는 제어, 데이터 관리, 데이터 구조를 통합하면서 객체 스토리지의 데이터를 저장하고 다양한 쿼리 및 변형 엔진을 지원한다.

- **데이터 레이크 하우스**: ACID 트랜잭션을 지원하고 클라우드 데이터 웨어하우스의 컴퓨팅과 스토리지 분리, 페타바이트 규모의 쿼리 지원, 다양한 비정형 및 반정형 데이터 저장, 스파크와 같은 고급 처리 기술 통합 가능.

현재 여러 벤더가 데이터 레이크와 데이터 웨어하우스 기능을 결합한 데이터 플랫폼을 제공하고 있다.

### 3.4.5 모던 데이터 스택
현재 유행하는 분석 아키텍처로 클라우드 기반의 플러그 앤 플레이 방식과 사용하기 쉬운 기성 구성 요소를 사용해 모듈화되고 비용 효율적인 데이터 아키텍처를 구축한다.

구성 요소:
- 데이터 파이프라인
- 스토리지
- 변환
- 데이터 관리/거버넌스
- 모니터링
- 시각화 및 탐색

목표는 복잡성을 줄이고 모듈화를 늘리는 것이다. 분석 엔지니어링에서 모던 데이터 스택은 데이터 아키텍처의 기본적인 선택이며 앞으로도 계속 사용될 것이다.

### 3.4.6 람다 아키텍처
데이터 엔지니어는 배치 및 스트리밍 데이터를 단일 아키텍처로 조정하는 방법을 찾아야 했으며, 람다 아키텍처는 이 문제에 대한 초기 대응 방법 중 하나였다.

구성 요소:
- **배치 처리**: 데이터 웨어하우스와 같은 시스템에서 데이터를 처리 및 변환하여 사전 계산 및 집계 뷰 생성.
- **스트리밍 처리**: NoSQL 데이터베이스에서 가능한 한 가장 낮은 지연 시간으로 데이터를 전달.
- **서빙 계층**: 배치와 스트리밍 계층에서 쿼리 결과를 집계하여 결합된 뷰 제공.

람다 아키텍처의 단점:
- 여러 시스템을 관리해야 하므로 매우 어렵고 오류가 발생하기 쉬운 시스템을 만들 수 있음.

람다 아키텍처는 여전히 주목받고 있지만, 분석을 위해 스트리밍 데이터와 배치 데이터를 결합하려는 경우 가장 먼저 권장하지는 않는다.

### 3.4.6 카파 아키텍처
카파 아키텍처는 스트림 처리 플랫폼을 데이터 처리, 저장 및 서빙 등 모든 데이터 처리의 백본으로 사용하는 것을 제안한다. 이를 통해 진정한 이벤트 기반 아키텍처를 실현할 수 있다. 실시간 이벤트 스트림을 직접 읽고 대량 데이터 청크를 재생해 일괄 처리함으로써 동일한 데이터에 실시간 및 배치 처리를 매끄럽게 적용할 수 있다.

카파 아키텍처의 채택이 낮은 이유:
- 스트리밍 자체가 많은 기업에 여전히 미지의 영역이다.
- 카파 아키텍처는 복잡하고 비용이 많이 든다.
- 배치 스토리지와 프로세싱은 방대한 데이터셋에 비해 훨씬 효과적이고 비용 효율적이다.

### 3.4.7 데이터 흐름 모델 및 통합 배치, 스트리밍
스트림 처리 관리의 주요 문제 중 하나는 여러 코드 경로를 통합하는 것이다. 카파 아키텍처는 통합 큐잉 및 스토리지 계층에 의존하지만, 실시간 통계를 수집하거나 배치 집계 작업을 실행하려면 다른 도구를 사용해야 한다.

구글의 데이터 흐름 모델과 이를 구현하는 아파치 빔 프레임워크:
- 모든 데이터를 이벤트로 간주하며, 다양한 유형의 윈도에서 집계를 수행한다.
- 지속적인 실시간 이벤트 스트림은 무한 데이터로 간주되며, 데이터 배치는 유한 이벤트 스트림으로 경계를 갖는다.

### 3.4.8 IoT용 아키텍처
사물인터넷(IoT)은 인터넷에 접속 가능한 장치들의 분산 컬렉션이다.

#### 장치
인터넷에 연결된 물리 하드웨어로, 주변 환경을 감지하고 데이터를 수집해 다운스트림 목적지로 전송한다. 장치는 최소한의 데이터 수집 및 전송 능력을 갖추어야 하며, 수집한 데이터에 대해 머신러닝을 실행할 수도 있다.

데이터 엔지니어는 IoT 장치의 내부 구조보다는 다음을 이해해야 한다:
- 수집하는 데이터와 전송 빈도.
- 에지 컴퓨팅 또는 머신러닝을 통한 데이터 처리 여부.
- 장치 또는 인터넷 장애, 환경적 요인 등이 데이터 수집에 미치는 영향.

### 3.4.9 데이터 메시
데이터 메시(Data Mesh)는 중앙집중식 데이터 아키텍처의 문제를 해결하기 위해 도메인 기반 설계 개념을 채택한 분산형 데이터 아키텍처이다.

데이터 메시의 핵심 구성 요소:
1. 도메인 지향 분산형 데이터 소유권 및 아키텍처.
2. 제품으로서의 데이터.
3. 플랫폼으로서의 셀프 서비스 데이터 인프라.
4. 통합 컴퓨팅 거버넌스.

더 자세한 내용은 [Data Mesh(O`Reilly,2022)]를 참조하자.

### 3.4.10 기타 데이터 아키텍처 예시
데이터 아키텍처에는 데이터 패브릭, 데이터 허브, 확장 아키텍처, 메타데이터 우선 아키텍처, 이벤트 기반 아키텍처, 라이브 데이터 스텝 등 수많은 종류가 있다. 새로운 아키텍처는 계속 등장할 것이다.

데이터 엔지니어는 새로운 아키텍처가 조직에 어떻게 도움이 되는지 주목하고, 데이터 엔지니어링 생태계 개발에 대한 높은 수준의 인식을 유지하며 새로운 개발 관련 정보를 계속 파악해야 한다.

## 3.5 데이터 아키텍처 설계 담당자는 누구인가?

데이터 엔지니어는 전담 데이터 아키텍트와 함께 일하는 것이 이상적이다. 그러나 기업의 규모가 작거나 데이터 성숙도가 낮은 경우, 데이터 엔지니어가 아키텍트 역할을 겸할 수 있다.

### 아키텍처 설계 시 고려 사항

- **비즈니스 관계자와 협력**
  - 트레이드 오프 평가
  - 비즈니스 요구사항 반영

- **고유 장단점 평가**
  - 클라우드 데이터 웨어하우스 vs 데이터 레이크
  - 다양한 클라우드 플랫폼의 트레이드 오프 (빔, 플링크 등)

- **프레임워크 사용 시기 평가**
  - 통합 배치 및 스트리밍 프레임워크

이러한 선택지를 추상적으로 연구하면 구체적이고 가치 있는 결정을 내릴 수 있다.

## 3.6 결론

### 데이터 아키텍처의 중요성

- **데이터 엔지니어링 수명 주기와의 부합**
- **우수한 데이터 아키텍처를 만드는 요소**

### 데이터 아키텍처의 예시

- 데이터 웨어하우스
- 데이터 레이크
- 데이터 레이크하우스
- 모던 데이터 스택
- 람다 아키텍처
- 카파 아키텍처
- 데이터 흐름 모델
- IoT용 아키텍처
- 데이터 메시

### 연구와 이해의 중요성

- 각 아키텍처의 트레이드 오프 이해
- 깊이 있는 연구를 통한 준비

조직의 고유한 요구 사항에 대응하는 아키텍처를 설계할 준비가 되어야 한다.

# 4. 데이터 엔지니어링 수명 주기 전체에 걸친 기술 선택

오늘날 데이터 엔지니어링은 다양한 기술 선택지로 인해 오히려 어려움을 겪고 있다. 데이터 엔지니어링의 핵심 목적은 데이터를 운반하고 최종 사용자의 요구에 따라 이를 제공하는 견고하고 신뢰성 높은 시스템 설계이다. 이를 위해 전략적 아키텍처와 전술적 도구의 선택이 중요하다.

## 4.1 팀의 규모와 능력

가장 먼저 평가해야 할 요소는 팀의 규모와 기술 역량이다.

- **팀의 규모와 역할**
  - 소규모 팀: 많은 역할을 수행해야 함
  - 대규모 팀: 각 구성원이 전문화된 역할 담당

- **기술 역량에 따른 도구 선택**
  - 소규모 팀/기술력이 약한 팀: 관리형 도구와 SaaS 도구 사용 권장
  - 기술 역량이 높은 팀: 복잡한 솔루션 도입 가능

- **팀의 기술 목록 작성**
  - 로우코드 도구 vs. 코드 우선 접근 방식
  - 특정 언어 (자바, 파이썬, Go 등) 능숙도

## 4.2 시장 출시 속도

기술 분야에서는 시장 투입 속도가 승패를 결정한다.

- **빠른 도구 선택**
  - 팀원들이 이미 잘 아는 도구 사용 권장
  - 신속하고 신뢰성 있게 작업 가능

- **완벽함은 우수함의 적**
  - 느린 결정과 산출물은 데이터 팀에 치명적

## 4.3 상호 운용성

다양한 기술 또는 시스템이 어떻게 연결되고 정보를 교환하며 상호작용하는지를 나타낸다.

- **통합 기능**
  - 데이터 수집 및 시각화 도구의 통합 기능 확인
  - 널리 사용되는 데이터 웨어하우스 및 데이터 레이크와의 통합
  - 인기 있는 데이터 수집 도구와 일반적인 API 및 서비스 통합

## 결론

데이터 엔지니어링에서 기술 선택은 팀의 규모와 능력, 시장 출시 속도, 상호 운용성을 고려해야 한다. 전략적 아키텍처와 전술적 도구 선택을 통해 조직의 고유한 요구에 맞는 견고하고 신뢰성 높은 데이터 시스템을 설계할 수 있다.

## 4.4 비용 최적화 및 비즈니스 가치

실제 환경에서 예산과 시간은 한정적이며, 특히 비용은 적절한 데이터와 기술 선택에 큰 제약 조건이다. 데이터 프로젝트에서 긍정적인 ROI를 기대하기 위해서는 제어 가능한 비용을 이해해야 한다. 기술 선택과 관리 전략은 예산에 큰 영향을 미치며, 총 소유 비용, 기회 비용, 핀옵스 관점에서 비용을 살펴보자.

### 4.4.1 총소유비용

#### 총소유비용(TCO)
총소유비용(TCO)은 활용되는 제품 및 서비스의 직접 비용과 간접 비용을 포함한 전체 추정 비용이다.
- **직접 비용**: 팀의 급여, 서비스 이용에 대한 청구서 등
- **간접 비용**: 프로젝트와 무관하지만 지불해야 하는 비용

#### 설비투자비용 (CAPEX)
설비 투자 비용에는 선행 투자가 필요하며, 초기 투자는 자산으로 간주되어 시간이 지남에 따라 감가상각이 이루어진다.
- **예산 조달**: 자본 필요
- **투입된 비용 관리**: 장기적 관점

#### 운영비용(OPEX)
운용 비용은 점진적이며 시간이 지남에 따라 분산된다.
- **단기적 비용**: 클라우드 기반 서비스 이용
- **유연성 고려**: 종량제 모델 선호

데이터 엔지니어는 유연성과 낮은 초기 비용을 고려해 클라우드와 유연한 종량제 기술을 중심으로 운영비용 우선 접근 방식을 취할 것을 권장한다.

### 4.4.2 총소유기회비용(TOCO)
총소유기회비용(TOCO)은 아키텍처 또는 프로세스를 선택할 때 발생하는 기회 상실 비용이다.
- **장기적 소유**: 클라우드 환경에서도 기술 스택 또는 파이프라인이 핵심이 되면 사실상 소유권을 갖게 됨
- **기회 비용 평가**: 새로운 프로젝트 수행 시 기회 비용을 고려하지 않으면 큰 맹점이 될 수 있음

기회 비용을 최소화하는 첫 번째 단계는 유연성이 높은 기술을 선택하는 것이다. 유연성이 떨어진 데이터 기술은 빠지기 쉽지만 탈출하기에는 매우 고통스럽다.

### 4.4.3 핀옵스

핀옵스(FinOps)의 목표는 시스템을 모니터링하고 동적으로 조정하는 데브옵스(DevOps)와 같은 방식을 적용해 재무적 책임과 비즈니스 가치를 최적화하는 것이다. 

데이터 엔지니어링 환경에서 신속하게 반복하고 동적으로 확정할 수 있는 기능은 비즈니스 가치를 창출하는 데 매우 중요하다. 이는 데이터 워크로드를 클라우드로 전환하는 주요 동기 중 하나이다.

핀옵스는 다음과 같은 요소를 포함한다:
- **모니터링**: 실시간으로 비용을 추적하고 분석하여 최적화할 수 있는 능력
- **동적 조정**: 사용량에 따라 자원을 조정하여 비용 효율성을 극대화
- **재무적 책임**: 모든 비용이 투명하게 관리되고 비즈니스 목표에 맞게 조정됨

핀옵스를 통해 데이터 엔지니어는 클라우드 비용을 효율적으로 관리하며, 예산을 초과하지 않도록 주의하면서도 필요한 리소스를 적시에 제공할 수 있다.

## 4.5 현재 vs 미래: 불변의 기술과 일시적 기술 비교

현재와 가까운 미래의 가장 적합한 기술을 선택하되, 미래의 변화와 진화에 대응할 수 있는 방식을 고려해야 한다. 무엇이 변화할 가능성이 높고 무엇이 동일하게 유지될지를 이해해야 한다.

거의 모든 기술은 필연적인 쇠퇴의 길을 걷게 된다.

### 4.5.1 조언

- 도구들과 모범 사례의 빠른 변화 속도를 고려해 2년마다 도구들을 평가할 것을 권장한다.
- 일시적인 도구들을 기반 기술 주위에 구축하자.
- 선택한 기술에서 다른 기술로의 전환이 얼마나 쉬운지를 고려해야 한다.
- 프로젝트가 무산되거나 회사가 존속할 수 없거나 기술이 더는 적합하지 않을 수도 있다는 사실을 인지하고, 눈을 크게 뜬 채 새로운 기술에 뛰어들자.

## 4.6 장소: 온프레미스, 클라우드, 하이브리드 클라우드, 멀티 클라우드

기술 스택을 실행할 장소를 결정할 때 다양한 선택지가 있다. 클라우드로 서서히 전환됨에 따라 AWS, Azure, Google Cloud Platform에서 워크로드를 빠르게 처리하는 기업들이 급증했다.

### 4.6.1 온프레미스

기존 기업들은 여전히 온프레미스 시스템을 기반으로 한다. 기업은 하드웨어와 하드웨어에서 실행된 소프트웨어의 운영 사항에 대한 책임을 진다. 온프레미스 시스템을 담당하는 데이터 엔지니어는 과소비 없이 최대 부하 및 대규모 작업에서 뛰어난 성능을 제공할 수 있는 대용량 시스템을 구입해야 한다. 기존 기업들은 자신들에게 도움이 되는 운영 관행을 확립해 왔지만, 젊고 민첩한 경쟁업체들이 클라우드 관리형 서비스의 장점을 누리는 것을 목격하고 있다. 모든 기업은 기존 시스템을 효율적으로 가동하면서 다음 조치를 결정해야 한다. 이는 온프레미스에서 하드웨어를 계속 실행하면서 컨테이너, Kubernetes, 마이크로서비스, 지속적 배포와 같은 새로운 DevOps를 채택하는 것을 포함할 수 있다.

### 4.6.2 클라우드

하드웨어를 구입하는 대신 클라우드 제공업체로부터 임대하기만 하면 된다. 이러한 자원은 매우 단기간으로 예약할 수 있다. 코드를 배포할 준비가 되면 바로 서버를 실행할 수 있다. 예산과 시간이 촉박한 스타트업에게 매우 매력적이다. SaaS 오퍼링은 한 단계 더 나아가 운영 관리가 거의 필요 없는 완전한 기능을 갖춘 엔터프라이즈 소프트웨어 플랫폼을 제공한다.

### 4.6.3 하이브리드 클라우드

클라우드로 마이그레이션 하는 기업이 늘어나면서 하이브리드 클라우드 모델의 중요성이 커지고 있다. 어떤 기업도 모든 워크로드를 하룻밤 사이에 마이그레이션할 수 없다. 하이브리드 클라우드 모델을 고려해야 하는 몇 가지 이유는 다음과 같다:

- 클라우드 환경에서 즉각적인 이점을 얻을 수 있는 특정 워크로드만 마이그레이션 할 수 있다.
- 클라우드의 분석을 배치하는 이러한 패턴은 데이터가 주로 한 방향으로 흐르면서 데이터 이그레스 비용을 최소화하므로 매우 유리하다.
- 온프레미스 애플리케이션은 기본적으로 무료 클라우드에 표시할 수 있는 이벤트 데이터를 생성한다.
- 대량의 데이터는 클라우드에 나와 분석되며, 소량의 데이터는 애플리케이션 모델을 배포하거나 역 ETL을 위해 온프레미스에 다시 전송된다.

## 4.6.4 멀티클라우드

멀티클라우드는 워크로드를 여러 퍼블릭 클라우드에 배포하는 것을 의미한다. 이를 통해 여러 클라우드에서 최고의 서비스를 활용할 수 있다. 다양한 클라우드 제공업체 간의 치열한 경쟁을 고려하면 매력적이다.

### 장점
- 여러 클라우드 서비스의 장점을 동시에 활용 가능

### 단점
- 데이터 이그레스 비용과 네트워킹 경목 현상이 매우 중요
- 여러 클라우드에 걸쳐 다양한 서비스를 관리해야 함
- 클라우드 간 통합법 보안 문제 발생 가능
- 네트워킹 복잡성 증가

## 4.6.5 탈중앙화: 블록체인과 엣지

엣지 컴퓨팅과 블록체인을 간단히 살펴볼 필요가 있다. 오늘날 애플리케이션은 주로 온프레미스와 클라우드에서 실행되지만, 블록체인과 웹 3.0, 엣지 컴퓨팅의 부상은 이러한 패러다임을 뒤집을 수도 있다.

## 4.6.6 조언

클라우드 자체는 변화하고 있다. 또한 새로운 워크로드 배치 추상화도 등장했다. 온프레미스 서비스는 점점 더 클라우드와 비슷해지고 추상화되고 있다. 서드파티 서비스와 퍼블릭 클라우드 벤더 주도로 클라우드의 클라우드가 형성되기 시작했다.

### 현재를 위한 기술을 선택하되 미래를 내다보자

현재는 워크로드 배치와 마이그레이션을 계획하기 어려운 시기다. 클라우드 업계의 경쟁과 변화 속도가 빠르기 때문에 5~10년 후에는 의사결정 공간이 크게 달라질 것이다.

하지만 끝없는 분석의 함정에 빠지지 않는 것이 중요하다. 현재의 요구사항에 최적인 기술을 선택하고 가까운 미래를 대비한 견고한 계획을 세우자. 단순함과 유연성을 중점에 두고 실제 비즈니스 요구에 따라 도입 플랫폼을 선택하자.

## 4.6.7 클라우드 송환 논쟁

진정한 클라우드 규모의 서비스를 실행하려면 온프레미스에서 워크로드를 계속 실행하거나 클라우드 워크로드를 송환하는 것을 고려해 보자. 클라우드 규모란 엑사바이트의 데이터를 저장하거나 초당 테라비트 단위의 인터넷 송수신 트래픽을 처리하는 경우를 말한다. 데이터 이그레스 비용이 비즈니스의 주된 요소일 때는 서버를 소유하는 것도 고려해 보자.

## 4.7 구축과 구매 비교

비즈니스의 경쟁 우위를 제공할 때 구축과 커스터마이징에 투자할 것을 제안한다. 그렇지 않다면 시장에서 이미 구할 수 있는 것을 이용하자. 오픈 소스 및 유료 서비스의 수를 고려했을 때 모든 것을 직접 구축하는 것은 어리석다.

과거에는 IT 부서가 대부분 소프트웨어 구입 및 채택 결정을 하향식으로 내렸지만, 최근에는 상향식 소프트웨어 채택이 추세다. 기업 내에서의 기술 도입은 점차 유기적이고 지속적인 프로세스가 되고 있다. 오픈소스 솔루션과 독점 솔루션에 관한 몇 가지 옵션을 살펴보자.

### 4.7.1 오픈 소스 소프트웨어(OSS)

오픈 소스 소프트웨어는 특정 라이센스 조건에 따라 소프트웨어 및 기본 코드 베이스를 일반 용도로 이용할 수 있도록 공개하는 소프트웨어 분산 모델이다.

오픈소스 소프트웨어를 만들고 유지 관리하는 동기는 다양하다. 때로는 개인이나 소규모 팀의 아이디어로부터 탄생하는 결과물이기도 하다. 새로운 솔루션을 만들고 공익을 위해 대중에게 공개하거나 회사가 라이센스에 근거해 특정 도구나 기술을 대중에게 공개하는 경우도 있다.

~p.202