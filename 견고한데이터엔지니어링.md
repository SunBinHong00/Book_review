# 1장 데이터 엔지니어링 상세

## 1.1 데이터 엔지니어링이란?

- **데이터 엔지니어링**:
  - 다른 전문가가 데이터를 사용할 수 있도록 만드는 일련의 작업.
  - 대규모 데이터 수집 및 저장.
  - 추가 분석을 수행할 수 있는 데이터를 준비하기 위한 시스템 설계 및 구축.

### SQL 중심

- 데이터 작업 및 기본 저장소는 RDS.
- 때때로 이러한 처리는 ETL 도구를 사용해 수행.

### 빅데이터 중심

- 데이터 작업 및 기본 스토리지:
  - 하둡, 카산드라, 스파크, 플링크.
- SQL이 사용되는 동안 기본 처리는 프로그래밍 언어로 이루어진다.

### 1.1.1 데이터 엔지니어링 정의

- **데이터 엔지니어링**:
  - Raw data를 가져와 분석 및 머신러닝 등 다운스트림 사용 사례를 지원.
  - 고품질의 일관된 정보를 생성하는 시스템과 프로세스 개발, 구현 및 유지 관리.
  - 보안, 데이터 관리, 데이터 운영, 데이터 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링.

### 1.1.2 데이터 엔지니어링 수명 주기

- **데이터 엔지니어링 수명 주기**:
  - 생성
  - 저장
  - 수집
  - 변환
  - 서빙

### 1.1.4 데이터 엔지니어링과 데이터 과학

- **학습/최적화**: AI, 딥러닝
- **집계/라벨링**: A/B 테스트, 실험, 단순 ML 알고리즘
- **탐색/변환**: 정제, 이상 감지, 준비
- **이동/저장**: 데이터 흐름, 인프라, 파이프라인, ETL, 정형/비정형 데이터 저장
- **수집**: 계측, 로깅, 센서, 외부 데이터, 사용자 생성 콘텐츠

**원천 시스템으로부터의 데이터 > 데이터 엔지니어링 > 데이터 과학과 분석**

## 1.2 데이터 엔지니어링 기술과 활동

- **데이터 엔지니어의 기술역량**:
  - 보안
  - 데이터 관리
  - 데이터옵스
  - 데이터 아키텍처 및 소프트웨어 엔지니어링
  - 최적화:
    - 비용
    - 민첩성
    - 확장성
    - 단순성
    - 재사용성
    - 상호 운용성

### 1.2.1 데이터 성숙도와 데이터 엔지니어

- **데이터 성숙도**:
  - 데이터 활용률, 기능, 통합
  - 데이터 관리 성숙도(DMM)

- **단순화된 기업용 데이터 성숙도 모델**:
  1. 데이터로 시작하기
  2. 데이터로 확장하기
  3. 데이터로 선도하기

#### 1단계: 데이터로 시작하기

- 이 단계에서 데이터 엔지니어는 보통 제너럴리스트.
- 데이터 엔지니어의 목표는 빠르게 움직이고, 견인력을 얻고, 부가가치를 창출.
- 데이터로부터 가치를 창출하는 일에 수요가 존재.
- 이 단계에서 ML에 먼저 뛰어들고 싶지만 권장하지 않음.

- **데이터 조직의 중점 사항**:
  - 경영진을 포함한 주요 관계자의 지원 확보.
  - 적절한 데이터 아키텍처 정의 및 구축.
  - 주요 이니셔티브를 지원하면서 데이터 검수.
  - 데이터 기반을 구축하여 보고서 및 모델 생성.

- **팁**:
  - 데이터로 가시적인 성공을 만들어 조직 의지를 유지.
  - 외부와 소통하며 관계자 피드백 수렴.
  - 과중한 업무 방지 및 불필요한 기술 복잡성 회피.
  - 경쟁 우위를 제공할 때만 맞춤형 솔루션 구축.

#### 2단계: 데이터로 확장하기

이번 과제는 확장성 있는 데이터 아키텍처를 구축하고, 기업이 진정으로 데이터 중심인 미래를 계획하는 것.

- **데이터 성숙도 2단계**:
  - 공식적인 데이터 관행 수립.
  - 확장성 있고 견고한 데이터 아키텍처 구축.
  - DevOps 및 DataOps 관행 채택.
  - ML을 지원하는 시스템 구축.
  - 차별화되지 않은 과중한 업무를 피하고 경쟁 우위를 확보할 때만 커스터마이징.

- **주의깊게 살펴볼 문제**:
  - 최신 기술을 무조건 추구하지 말고 고객 가치에 집중.
  - 클러스터 노드 스토리지보다 데이터 엔지니어링 팀이 병목 현상.
  - 실용적인 리더십으로 데이터 활용법을 교육.

#### 3단계: 데이터로 선도하기

- **데이터 성숙도 3단계**:
  - **자동 배포**: 자동으로 새로운 데이터를 구축 및 배포.
  - **사용자 정의 도구와 시스템 구축**: 경쟁력을 위한 커스텀 도구 개발.
  - **데이터 관리 및 기업적 측면**: 기업 측면에 집중.
  - **데이터 노출 및 전파**:
    - 데이터 카탈로그, 데이터 계보 도구, 메타데이터 관리 시스템을 통해 노출 및 전파.
  - **효율적인 협업**: 엔지니어, 머신러닝 전문가와 협업.
  - **협업 커뮤니티 구축**:
    - 역할이나 직책에 상관없이 커뮤니티 형성.

- **주의깊게 살펴볼 문제**:

  1. **현재 상태 안주**:
     - 2단계에서 현재 상태에 안주하는 것은 큰 위험.
     - 조직이 3단계에 도달하면 유지보수와 개선에 집중.

  2. **기술의 산만함**:
     - 2단계에서 기술의 산만함은 위험 요소.
     - 비즈니스 가치를 제공하지 않는 취미 프로젝트는 피함.
     - 경쟁 우위를 제공할 때만 직접 기술을 활용.

### 1.2.2 데이터 엔지니어의 배경과 기술

- **데이터 엔지니어가 되는 방법**에는 많은 의문점이 있지만 공식화된 경로는 없습니다. 그럼에도 데이터 엔지니어가 성공하기 위해 필수적인 지식은 있습니다.  
- 데이터 엔지니어는 데이터와 기술 모두에 능통해야 합니다:
  - **데이터 측면**: 데이터 관리에 대한 모범 사례 이해.
  - **기술 측면**: 다양한 도구, 옵션, 상호작용, 상충 관계 이해.  
  - **기타 측면**: 소프트웨어 엔지니어링, 데이터 옵스, 데이터 아키텍처에 대한 이해.

- **요약**:
  - 데이터 엔지니어는 데이터 소비자들의 요구사항과 조직의 데이터 전체를 잘 이해해야 합니다.
  - 데이터 엔지니어링은 실용적인 업무이며, 최고의 데이터 엔지니어는 비즈니스와 기술 관점에서 그들의 책임을 판단합니다.

### 1.2.3 비즈니스 책임

- **커뮤니케이션**:
  - 비기술자 및 기술자와의 소통 방법 파악.
  - 조직 전체의 관계 형성과 신뢰 구축이 중요하며, 이는 성공의 핵심입니다.

- **비즈니스 및 제품 요건 이해**:
  - 이러한 요건이 기술로만 해결된다는 믿음은 위험할 정도로 잘못된 생각입니다.
  - 애자일, 데브옵스, 데이터옵스는 조직 전체에 걸친 동의가 필요한 문화적 요소입니다.

- **비용 관리**:
  - 가치 제공과 동시에 비용 절감에 성공하면 훌륭한 성과입니다.
  - 가치, 시간, 총 소유 비용, 기회 비용에 맞게 최적화해야 합니다.
  - 예상치 못한 상황을 방지하기 위해 비용 모니터링 방법을 배우세요.

- **지속적 학습**:
  - 데이터 분야는 빠르게 변화하고 있습니다.
  - 토대가 되는 기본 지식과 새로운 것을 습득하는 능력을 함께 키워야 합니다.
  - 데이터 흐름에 뒤처지지 않고 학습하는 방법을 습득하세요.

 성공적인 데이터 엔지니어는 항상 전체적인 큰 그림을 이해하고 비즈니스 가치를 극대화하는 방법을 파악하고자 한다 커뮤니케이션은 기술자 비기술자 모두에게 필수 요소다 데이터 팀은 다른 이해관계자와의 커뮤니케이션을 바탕으로 성공한 경우가 많으며 따라서 성공이나 실패의 여부가 기술적인 이슈에 따라 결정되는 경우가 거의 없다 조직을 탐색하고 요건을 파악하고 비용을 관리하고 지속해서 학습하는 방법을 알면 경력을 쌓고자 기술적 능력에만 의존한 데이터 엔지니어와 차별화 할 수 있다.


### 1.2.4 기술 책임

- **아키텍처 최적화**: 성능과 비용을 최적화하는 아키텍처 구축 필요.
- **데이터 엔지니어링 수명 주기 지원**:
  - 데이터 생성, 저장, 수집, 변환, 서빙의 각 단계 지원 필요.
  - 보안, 데이터 관리, 옵스, 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링 중요성 강조.

- **전문 기술 요구**: 상용 제품 수준의 소프트웨어 엔지니어링 기술 갖출 것.
  - 고수준 추상화와 코드 파이프라인 작성에 집중.

#### 데이터 엔지니어의 주요 언어

1. **SQL**:
   - 데이터 레이크의 일반적인 인터페이스.
   - 스파크 SQL, 스노우플레이크, 하이브 등 다양한 도구 활용 필요.
   - 데이터 변환 및 분석 문제 신속 해결 가능.
   - 스파크, 프링크 등 프레임워크 내에서 SQL 활용, 최신 SQL 문법 습득 요구.

2. **Python**:
   - 판다스, 넘파이, 에어플로우 등 주요 데이터 도구 기반.
   - 많은 데이터 엔지니어링 도구가 파이썬 API 제공함.

3. **JVM 언어**:
   - 스파크, 하이브, 드루이드 등에서 사용됨.
   - 파이썬보다 성능이 우수하며 저수준 특성에 접근할 수 있음.

4. **Bash**:
   - 리눅스 CLI용 스크립트 작성 및 명령 수행에 필수.
   - Bash 능숙하면 생산성 및 워크플로우 향상됨.

#### 빠르게 변화하는 분야 대응 방법
- **기본 개념 이해**와 **새로운 패러다임 학습** 병행 필요.
- **지속적인 기술 개발**로 업계 흐름 파악 및 적응 요구.


### 1.2.5 A에서 B로 이어진 데이터 엔지니어링 역할의 연속성

데이터 엔지니어링의 역할은 다양하며 모든 데이터 엔지니어가 같은 유형의 작업을 수행하거나 같은 기술을 보유하지 않음. 데이터 성숙도는 기업 내 데이터 역량을 확장함에 따라 직면할 데이터 문제 유형을 이해하는 데 도움을 제공.

#### A형 데이터 엔지니어
- **추상화(Abstraction)**:
  - 차별화되지 않은 과중한 작업을 피하고, 데이터 아키텍처를 가능한 한 추상적이고 단순하게 유지하여 시간 낭비 방지.
  - 주로 시판되는 기성 제품, 관리형 서비스와 도구들을 사용해 데이터 엔지니어링 주기 관리.
  - 데이터 성숙도 수준에 상관없이 산업 전반에 걸쳐 다양한 회사에서 활동.

#### B형 데이터 엔지니어
- **구축(Build)**:
  - 기업의 핵심 역량과 경쟁 우위를 확장하고 활용할 데이터 도구와 시스템 구축.
  - B형 데이터 엔지니어는 데이터 성숙도에서 2단계 및 3단계에 해당하거나 초기 데이터 사용 사례가 독특하고 중요해서 맞춤형 데이터 도구가 필요한 회사에서 자주 발견됨.

#### A형과 B형 데이터 엔지니어의 연계성
- 같은 회사에서 근무하거나 동일 인물일 수도 있음.
- 일반적으로 A형 데이터 엔지니어가 기반 확립을 위해 먼저 채용되며, B형 데이터 엔지니어 기술은 사내에서 필요에 따라 학습하거나 새로운 인재를 고용하여 해결.

## 1.3 조직 내 데이터 엔지니어

### 1.3.1 내부 vs 외부 대면 데이터 엔지니어

- **서비스 대상 이해**:
  - 데이터 엔지니어는 누구에게 서비스를 제공하는지 이해해야 함
  - 주요 업무는 외부 대면, 내부 대면 또는 둘의 혼합일 수 있음

- **외부 대면 데이터 엔지니어**:
  - **역할**: 소셜 미디어 앱, 사물 인터넷, 전자상거래 플랫폼 등 외부 애플리케이션 사용자와 연결함
  - **업무**: 트랜잭션 및 이벤트 데이터를 수집, 저장, 처리하는 시스템을 설계, 구축, 관리함
  - **시스템 특징**: 애플리케이션과 데이터 파이프라인 간 피드백 루프가 있음

- **외부 대면 데이터 엔지니어링의 문제**:
  - **동시성 부하**: 외부 쿼리는 내부 시스템보다 큰 동시성 부하를 처리해야 함
  - **쿼리 제한**: 사용자 쿼리를 제한해 단일 사용자의 인프라 영향을 최소화해야 함
  - **보안 문제**: 보안은 복잡하고 민감하며 특히 멀티테넌트 데이터의 경우 더욱 그렇다

- **내부 대면 데이터 엔지니어**:
  - **집중 영역**: 비즈니스 및 내부 이해관계자의 요구 사항에 집중함
  - **업무**: BI 대시보드, 보고서, 데이터 과학, 머신러닝 모델용 데이터 파이프라인, 데이터 웨어하우스의 생성 및 유지보수를 담당함

- **혼합 업무**:
  - 외부 및 내부 대면 업무는 혼합될 수 있음
  - 데이터 엔지니어는 쿼리 동시성이나 보안 등 요구 사항이 다른 두 그룹을 관리해야 함

### 1.3.2 데이터 엔지니어와 기타 기술 역할

- **업스트림 데이터 생산자**:
  - **소프트웨어 엔지니어**: 비즈니스를 운영하는 소프트웨어와 시스템을 구축하며, 데이터 엔지니어가 사용하는 내부 데이터의 생성에 큰 책임을 가짐. 주로 애플리케이션 이벤트 및 로그 데이터를 생성하며, 데이터 엔지니어와 협력해 신규 프로젝트 초기에 어플리케이션 데이터를 설계
  - **데이터 아키텍트**: 조직의 데이터 관리를 위한 청사진을 설계하며, 데이터 관리와 거버넌스 정책을 수립하고, 전사적인 데이터 관리 전략을 조율. 클라우드 마이그레이션과 신규 클라우드 설계에 핵심적인 역할을 담당
  - **데브옵스 및 사이트 신뢰성 엔지니어**: 운영 모니터링을 통해 데이터를 생성하며, 업스트림 이해관계자로 분류되지만 데이터 시스템 운영을 조정할 때 데이터 엔지니어와 소통하는 다운스트림 역할도 함

- **다운스트림 데이터 소비자**:
  - **데이터 분석가**: 비즈니스 성과와 동향을 파악하기 위해 데이터 웨어하우스나 데이터 레이크에서 SQL 쿼리를 실행하고 스프레드시트나 다양한 BI 도구를 활용. 비즈니스 사용자, 경영진 및 임원 등의 니즈에 맞춰 데이터를 분석하며, 데이터 엔지니어와 협력해 필요한 데이터 원천 파이프라인을 구축
  - **데이터 과학자**: 예측과 추천을 위한 미래지향적인 모델을 구축하며, 데이터 수집, 정제, 준비에 전체 업무 시간의 70-80%를 소모. 확장 가능한 프레임워크가 없다면 데이터 다운샘플링으로 인한 데이터 품질 저하의 위험이 있음. 데이터 엔지니어는 데이터 과학자의 작업 경로를 최적화하여 작업 결과물을 더 쉽게 만들 수 있도록 지원
  - **머신러닝 엔지니어 및 인공지능 연구원**: 고급 머신러닝 기술을 개발하고 모델을 훈련하며, 확장된 운영 환경에서 머신러닝 프로세스를 실행하는 인프라를 설계 및 유지. 딥러닝 프레임워크에 대한 전문 지식을 갖추고 있으며, 데이터 과학자와 협력해 고급 머신러닝 프로세스를 설계

- **데이터 엔지니어의 허브 역할**:
  - 데이터 생산자와 소비자 사이의 허브 역할을 수행하며, 생산과 소비 간 피드백 루프를 관리. 운영 역할을 담당하는 데브옵스 엔지니어와도 소통하며 데이터 시스템 전반을 관리

#### 업스트림 이해관계자

- **데이터 아키텍트**:
  - 데이터 엔지니어와 유사한 추상화 수준에서 작업하며, 조직 데이터 관리를 위한 청사진을 설계
  - 데이터 아키텍처 및 시스템을 맵핑하여 프로세스 전체를 감독
  - 기술적 및 비기술적 측면을 연결하는 가교 역할을 수행
  - 데이터 관리 및 거버넌스 정책을 수립하고 전사적인 전략을 조율
  - 클라우드 마이그레이션과 신규 클라우드 설계에 핵심적인 역할을 담당

- **소프트웨어 엔지니어**:
  - 비즈니스에 필요한 소프트웨어와 시스템을 구축
  - 내부 데이터의 생성 업무를 책임지고, 애플리케이션 이벤트 및 로그 데이터 제공
  - 데이터 엔지니어와 협력해 신규 프로젝트의 초기 단계부터 애플리케이션 데이터를 설계
  - 애플리케이션 데이터의 양, 빈도, 형식, 보완 및 규정 준수 등 데이터 엔지니어링 수명 주기에 영향을 미치는 모든 요소를 파악

- **데브옵스 엔지니어 및 사이트 신뢰성 엔지니어**:
  - 운영 모니터링을 통해 데이터를 생성하며, 데이터 엔지니어의 업스트림 역할을 수행
  - 때로는 데이터 시스템 운영을 조정하며 데이터 엔지니어와 직접 소통하는 다운스트림 역할도 수행

#### 다운스트림 이해관계자

- **다양한 역할**:
  - 데이터 엔지니어가 다운스트림 역할과 소통하는 방법을 다룸
  - 중앙집중식 데이터 엔지니어링 팀 및 서비스 모델도 소개



- 데이터 과학자

  - **모델 구축**:
    - 미래지향적인 예측 및 추천 모델 구축
    - 데이터 수집, 정제, 준비에 업무 시간의 70~80%를 소비

  - **병목 현상과 품질 저하 문제**:
    - 단일 워크스테이션에서 작업 시 데이터 다운샘플링이 발생하며 모델 품질 저하 가능
    - 로컬에서 개발한 코드는 실제 운용 환경 배포에 어려움이 있음
    - 자동화 부족 시 데이터 워크플로우 방해

  - **제품 단계 데이터 과학의 필요성**:
    - 데이터 전문가의 역할을 강조
    - 데이터 엔지니어가 데이터 과학자의 작업 결과물을 제작할 경로를 설정할 수 있도록 지원해야 함

- 데이터 분석가

  - **업무 및 도구**:
    - 비즈니스 성과와 동향 파악
    - 데이터 웨어하우스나 데이터 레이크에서 SQL 쿼리 실행
    - 계산 및 분석에 스프레드시트, BI 도구 사용
    - 주요 고객은 비즈니스 사용자, 경영진, 임원

  - **협업**:
    - 데이터 엔지니어와 협업해 새로운 데이터 원천용 파이프라인 구축
    - 주제별 전문 지식으로 데이터 품질 개선에 기여

- 머신러닝 엔지니어 및 인공지능 연구원

  - **역할 및 전문성**:
    - 데이터 엔지니어, 데이터 과학자와 겹치는 부분이 많음
    - 고급 머신러닝 기술 개발, 모델 훈련, 인프라 설계 및 유지
    - 파이토치, 텐서플로우 등 딥러닝 프레임워크에 대한 실무 지식 보유

  - **운영 환경**:
    - 모델 훈련과 배포에 필요한 하드웨어, 서비스 및 시스템 이해
    - 머신러닝 시스템 운영 환경에 책임을 질 수 있음

  - **경계의 모호함**:
    - 머신러닝 엔지니어링, 데이터 엔지니어링, 데이터 과학 사이 경계가 모호함
    - 데이터 엔지니어와 긴밀히 협업하여 고급 머신러닝 프로세스를 설계

### 1.3.3 데이터 엔지니어와 비즈니스 리더십
  - 기업은 데이터 활용을 확대하며 데이터 엔지니어는 전략적 계획에 참여하고 IT를 넘어 주요 이니셔티브를 주도함
  - 데이터 아키텍트를 지원하며 비즈니스와 데이터 과학, 분석의 결합체로서 역할 수행

- **데이터 엔지니어와 프로젝트 매니저**
  - **역할**:
    - 데이터 엔지니어는 클라우드 마이그레이션, 차세대 데이터 아키텍처 구축 등 장기 프로젝트에 참여
    - 신규 프로젝트에서 최적의 아키텍처 및 도구 선택, 새로운 데이터 아키텍처 구성
    
  - **프로젝트 매니저와의 협업**:
    - 데이터 엔지니어는 인프라 및 서비스 제공에 능력을 발휘
    - 프로젝트 매니저는 트래픽 총괄, 게이트키퍼 역할, 애자일·스크럼 방식 운영
    - 중요한 성과물에 우선순위 부여

- **데이터 엔지니어와 제품 관리자**
  - **역할**:
    - 제품 관리자는 제품 개발 감독 및 제품 라인 관리
    - 데이터 엔지니어는 제품 관리자와 협력해 데이터 제품 개발
    
  - **균형 조절**:
    - 제품 관리자는 기술팀과 고객, 비즈니스 요구 간 균형을 유지
    - 프로젝트 매니저처럼 데이터 엔지니어와의 협업 중요

- **다른 매니저와의 협업**
  - 데이터 엔지니어는 프로젝트 매니저 및 제품 관리자 외에도 다양한 매니저와 소통
  - 일반적으로 서비스 또는 교차 기능 모델을 따르며 다양한 요청을 처리
  - 특정 관리자, 프로젝트 또는 제품에 할당된 자원으로 작업


## 1.4 결론

1장에서는 데이터 엔지니어링 환경의 개요를 다음과 같이 간략하게 설명했다

- **데이터 엔지니어링의 정의와 역할**:
  - 데이터 엔지니어링이란 무엇인지와 데이터 엔지니어가 하는 일에 대해 설명

- **기업의 데이터 성숙도 유형**:
  - 기업의 데이터 성숙도 유형과 그 차이를 이해

- **A형과 B형 데이터 엔지니어**:
  - 두 유형의 데이터 엔지니어 특성과 역할 비교

- **데이터 엔지니어 협업 대상**:
  - 데이터 엔지니어가 협업하는 업스트림 및 다운스트림 이해관계자, 프로젝트 매니저, 제품 관리자 등 다양한 역할 소개

# 2 데이터 엔지니어링 수명 주기

## 2.1 데이터 엔지니어링 수명 주기란?

데이터 엔지니어링 수명 주기는 다음 5단계로 나눌 수 있다:
- **데이터 생성**
- **데이터 수정**
- **데이터 수집**
- **데이터 변환**
- **데이터 서빙**

데이터 저장은 수명 주기 전체에 걸쳐 일어난다. 데이터의 흐름은 깔끔하고 일정하지 않으며 수명 주기의 여러 단계가 반복, 순서가 어긋나거나 겹치기도 한다. 예상치 못한 방식으로 조합될 수 있다.

이 수명 주기에는 여러 필수 요소가 전반에 걸쳐 존재한다:
- **보안**
- **데이터 관리**
- **데이터 옵스**
- **데이터 아키텍처**
- **오케스트레이션**
- **소프트웨어 엔지니어링**

이러한 요소가 없다면 수명 주기의 어떤 부분도 제대로 작동하지 않는다.

### 2.1.1 데이터 생성

원천 시스템은 데이터 엔지니어링 수명 주기에서 사용되는 데이터의 원본이다. 원천 시스템은 예를 들어 IoT 장치, 어플리케이션, 메시지 대기열, 트랜잭션 데이터베이스 등이 될 수 있다. 데이터 엔지니어는 원천 시스템의 데이터를 사용하지만, 원천 시스템 자체를 소유하거나 제어하지 않는다. 이들은 데이터 생성 방식, 데이터 빈도 및 속도, 생성되는 데이터의 다양성을 잘 이해해야 한다.

데이터 엔지니어는 원천 시스템 소유자와 개방적인 소통 라인을 유지해 변경 사항이 파이프라인과 분석에 영향을 주지 않도록 해야 한다. 데이터 엔지니어가 이해해야 하는 다양한 데이터 원천 시스템이 있기 때문에, 이를 평가할 때 주요 고려 사항은 다음과 같다:

- **데이터 원천의 특성**: 원천이 어플리케이션인가, IoT 장치인가?
- **데이터 유지 방식**: 데이터가 오래 보존되는가, 아니면 일시적이고 빠르게 삭제되는가?
- **데이터 일관성**: 출력 데이터에서 어느 정도 일관성을 기대할 수 있는가? 데이터 품질 검사를 실행할 때 오류 데이터나 이상치가 얼마나 자주 나타나는가?
- **에러 빈도**: 데이터 에러는 얼마나 자주 발생하는가?
- **중복 여부**: 데이터의 중복이 있는가?
- **지연 도착**: 일부 데이터 값이 다른 메시지보다 훨씬 늦게 도착할 수 있는가?
- **데이터 스키마**: 데이터 엔지니어가 완전히 파악하려면 여러 테이블 또는 시스템 간의 조인이 필요한가?
- **스키마 변경**: 스키마가 변경되면 어떻게 대처하고 다음 스트림 이해관계자에게 전달할 것인가?
- **데이터 수집 빈도**: 원천 시스템의 데이터를 얼마나 자주 가져와야 하는가?
- **상태 있는 시스템**: 데이터가 정기적인 스냅샷으로 제공되는가, 아니면 변경 데이터 캡처 이벤트로 제공되는가? 변경 사항은 어떻게 추적되는가?
- **업스트림 의존성**: 원천 시스템에 업스트림 데이터 의존 관계가 있는가? 해당 시스템의 특성은 무엇인가?
- **데이터 품질 검사**: 늦거나 누락된 데이터를 확인하기 위한 데이터 품질 검사가 실시되고 있는가?
---
- **원천 시스템의 한계 이해**:
  - 데이터 엔지니어는 원천 어플리케이션에서 분석 쿼리가 자원 경험 및 성능 문제를 일으킬 수 있는지 이해해야 함. 원천 어플리케이션의 분석 작업이 시스템 성능에 영향을 미칠 수 있으므로, 이를 고려한 데이터 처리 방법이 필요함.

- **원천 데이터의 스키마 처리 방식**:
  - 원천 시스템은 데이터의 스키마를 다양한 방식으로 처리할 수 있음. 주요 방식으로는 스키마리스 방식과 고정 스키마 방식이 있음.
  
  - **스키마리스 방식**:
    - 예: 몽고DB와 같은 도큐먼트 데이터베이스에서 사용. 데이터 기록 시 스키마를 따로 정의하지 않으며, 데이터 자체에 스키마 정보를 포함시킬 수 있음.
  
  - **고정 스키마 방식**:
    - 관계형 데이터베이스 스토리지를 사용하는 경우, 데이터베이스에 적용된 고정된 스키마를 따라야 함. 어플리케이션 쓰기 작업은 이 스키마를 준수해야 함.

- **스키마의 진화**:
  - 스키마는 시간이 지남에 따라 변할 수 있음. 데이터 엔지니어의 주요 작업 중 하나는 원천 시스템의 스키마에서 원시 데이터를 받아 분석에 유용한 형태로 변환하는 것임.
  - 원천 스키마가 진화함에 따라 데이터를 적절히 처리하고 변환하는 작업이 더욱 복잡해질 수 있음.

### 2.1.3 데이터 저장

데이터 저장에 대한 몇 가지 주요 고려 사항은 다음과 같습니다:

1. **클라우드 데이터 아키텍처**:
   - 여러 스토리지 솔루션을 활용함.
   - 순수 스토리지뿐만 아니라 복잡한 데이터 변환을 지원하는 경우가 많음.
   - 데이터 수명 주기의 여러 단계에 참여함 (수집, 변환, 서비스 제공 등).

2. **스토리지 시스템 평가: 주요 엔지니어링 고려 사항**:
   - **쓰기 및 읽기 속도**:
     - 스토리지가 아키텍처가 요구하는 쓰기 및 읽기 속도를 충족하는지 확인.
     - 스토리지가 다운스트림 프로세스의 병목 현상을 초래하지 않는지 확인.

   - **작동 방식 이해**:
     - 스토리지 시스템이 작동 방식을 인지하고 최적으로 활용하는지 확인.
     - 객체 스토리지 시스템에 과도한 접근 및 갱신이 적용되지 않도록 주의.

   - **확장성**:
     - 향후 예상되는 확장을 처리할 수 있는지 평가.
     - 용량 제한을 고려하고 읽기 속도, 쓰기 볼륨 등도 함께 고려.

   - **메타데이터 캡처**:
     - 스키마 진화, 데이터 흐름, 데이터 계보 등에 대한 메타데이터를 캡처.
     - 메타데이터는 검색 기능과 제도적 지식을 향상시켜 미래 프로젝트 및 아키텍처 변경을 간소화.

   - **쿼리 패턴 지원**:
     - 순수 스토리지 솔루션인지, 복잡한 쿼리 패턴을 지원하는지 확인.

   - **스키마 적합성**:
     - 스키마에 유연성이 있는지 확인. 강제된 스키마는 유연성을 저해할 수 있음.

   - **데이터 거버넌스**:
     - 마스터 데이터, 골든 레코드, 데이터 품질, 데이터 계보를 어떻게 추적하는지 확인.

   - **법령 준수**:
     - 특정 지리적 위치에만 데이터를 저장하고 다른 곳에는 저장하지 않을 수 있는가? 데이터 주권과 법령 준수를 위한 전략을 수립.


---
#### 데이터 접근 빈도 이해

데이터 접근 빈도에 따라 데이터의 온도가 결정됩니다:

- **핫 데이터**: 가장 자주 액세스되는 데이터.
- **미온적 데이터**: 가끔씩만 액세스되는 데이터.
- **콜드 데이터**: 거의 액세스되지 않으며, 아카이브 시스템에 저장하기에 적합. 규정 준수 목적으로 보관되거나, 장애 시 복구를 위해 사용될 수 있음.

#### 스토리지 시스템 선택

어떤 유형의 스토리지 솔루션을 선택해야 할까요? 이에 대한 결정은 여러 요소에 따라 달라집니다:

- **사용 사례**: 데이터 수집 및 액세스 방식에 따라 스토리지 요구 사항이 달라짐.
- **데이터 볼륨**: 데이터의 총량에 따라 스토리지 크기와 비용이 영향을 받음.
- **수집 빈도**: 데이터가 얼마나 자주 수집되는지에 따라 스토리지 시스템의 성능 요구 사항이 결정됨.
- **데이터 형식 및 크기**: 구조화된 데이터와 비구조화된 데이터의 차이, 데이터 파일 크기에 따른 스토리지 전략이 필요함.

모든 스토리지 기술은 장단점, 즉 트레이드오프가 있습니다. 수많은 스토리지 기술 중 데이터 아키텍처에 가장 적합한 옵션을 찾을 때는 이런 점을 고려해야 합니다.

### 2.1.4 데이터 수집

데이터 원천과 사용 중인 원천 시스템의 특징 및 데이터 저장 방법을 이해한 후, 데이터를 수집하는 것이 중요합니다. 데이터 엔지니어링 수명 주기의 다음 단계는 원천 시스템에서 데이터를 수집하는 것입니다.

원천 시스템은 직접 관리하기 어렵고, 응답하지 않거나 품질이 낮은 데이터를 제공할 수 있습니다. 또한 여러 이유로 데이터 수집 서비스가 제대로 작동하지 않아 데이터 흐름이 멈추거나 필요한 데이터가 충분히 제공되지 않을 수 있습니다.

#### **수집 단계의 주요 엔지니어링 고려 사항:**
- **사용 사례**: 수집 중인 데이터의 사용 사례는 무엇인가? 여러 버전의 데이터셋을 생성하는 대신 재사용이 가능한가?
- **데이터 목적지**: 수집 후 데이터의 최종 목적지는 어디인가?
- **접근 빈도**: 데이터에 얼마나 자주 접근해야 하는가?
- **데이터 용량**: 데이터는 보통 어떤 용량으로 도착하는가?
- **데이터 형식**: 데이터 형식은 무엇이며, 다운스트림 시스템에서 처리할 수 있는가?
- **유효 상태**: 원천 데이터는 다운스트림에서 바로 사용할 수 있는 유효 상태인가? 사용 기간과 사용 불가능해지는 주요 요인은 무엇인가?
- **데이터 변환**: 데이터가 스트리밍 소스에서 전송되면, 목적지에 도달하기 전에 변환이 필요한가? 스트리밍 자체에서 변환하는 것이 적절한가?


#### **배치 vs 스트리밍**

- **스트리밍**:
  - 우리가 다루는 대부분의 데이터는 본질적으로 스트리밍 방식입니다.
  - 스트리밍 수집을 통해 다른 애플리케이션, 데이터베이스, 분석 시스템 등 다운스트림 시스템에 데이터를 실시간으로 연속해 제공할 수 있습니다.
  - **실시간**이란 데이터가 생성된 지 얼마 지나지 않은 짧은 시간 내에 다운스트림 시스템에서 데이터를 사용할 수 있는 것을 의미합니다.

- **배치**:
  - 배치 데이터는 미리 설정된 시간 간격이나 크기 임계값에 도달하면 수집됩니다.
  - 배치 수집은 한 방향으로만 진행되며, 데이터가 배치로 분할되면 다운스트림 소비자의 지연 시간이 제한됩니다.
  - 배치 처리는 분석 및 머신러닝에 다운스트림을 사용할 때 매우 인기 있는 방법입니다.

#### 배치와 스트림 수집의 주요 고려 사항

1. **실시간 데이터 처리**:
   - 데이터를 실시간으로 수집할 경우, 다운스트림 스토리지 시스템이 데이터 흐름 속도를 처리할 수 있는가?

2. **실시간 데이터 필요성**:
   - 밀리초 단위의 실시간 데이터가 필요한가? 아니면 매분 데이터를 축적하는 마이크로 배치 접근이 더 효과적인가?

3. **스트리밍 수집의 이점**:
   - 스트리밍 수집을 통해 얻을 수 있는 구체적인 이점은 무엇인가?
   - 데이터를 실시간으로 수집함으로써 배치 방식에 비해 개선될 수 있는 부분은 무엇인가?

4. **비용과 유지보수**:
   - 스트리밍 방식이 배치 방식보다 시간, 비용, 유지보수, 다운타임, 기회 비용 측면에서 더 많은 비용을 소모하는가?

5. **안정성과 다중화**:
   - 인프라에 장애가 발생할 때, 스트리밍 파이프라인과 시스템은 안정적이고 다중화되어 있는가?

6. **적합한 도구 선택**:
   - 관리형 서비스를 사용할지, 자체 인프라로 Kafka, Flink, Spark, Pulsar 등의 인스턴스를 구축할지 결정해야 함.
   - 관리 비용과 이점은 무엇인가?

7. **머신러닝 활용**:
   - 머신러닝 모델을 배포할 때 온라인 예측 및 지속적인 훈련으로 얻을 수 있는 이점은 무엇인가?

8. **원천 시스템 영향**:
   - 실 운영 인스턴스에서 데이터를 가져올 경우, 수집 프로세스가 원천 시스템에 미칠 영향은 얼마나 될까?

**결론**:
- 스트리밍 수집 방식은 좋은 아이디어처럼 보일 수 있지만, 추가 비용과 복잡성이 발생할 수 있습니다.
- 배치 및 마이크로 배치 수집 프레임워크는 효율적일 수 있습니다.
- 배치 사용의 트레이드오프를 이해하고 비즈니스 사용 사례를 정확하게 파악한 후에 스트리밍 수집 방식을 채택하는 것이 좋습니다.


### 2.1.5 데이터 변환

데이터를 수집하고 저장한 후, 이를 활용하기 위해 데이터 엔지니어링 수명 주기의 다음 단계인 **변환**을 진행해야 합니다. 데이터를 원래의 형태에서 다운스트림 사용 사례에 유용한 형태로 변경함으로써, 데이터가 가치 있는 정보로 변모하는 시작 단계입니다.

1. **기본 변환**:
   - 데이터를 올바른 형태로 맵핑하고, 레코드를 표준 형식으로 지정하며, 잘못된 유형은 제거.
   - 이후 단계에서는 데이터 스키마를 변환하고 정규화.

2. **변환 단계에서의 주요 고려 사항**:
   - **비용과 ROI**:
     - 변환 비용과 투자 수익률을 고려하고, 이와 관련된 비즈니스 가치는 무엇인가?

   - **단순하고 독립적**:
     - 변환 작업은 가능한 한 단순하고 독립적인지 고려.

   - **비즈니스 규칙**:
     - 변환이 어떤 비즈니스 규칙을 지원하는지 파악.

3. **배치 vs 스트리밍 변환**:
   - **배치 변환**: 여전히 압도적으로 인기 있지만, 스트리밍 데이터의 증가에 따라 스트리밍 변환도 계속 인기를 얻고 있습니다.
   - **스트리밍 변환**: 특정 도메인에서 배치 처리를 완전히 대체할 가능성이 있음.

4. **변환의 일반적 위치**:
   - **원천 시스템에서 변환**: 데이터 수집 중에 변환되거나 스트리밍 파이프라인 내에서 추가 필드와 계산을 통해 보강.
   - **다양한 위치**: 데이터 준비, 정규화 등 여러 작업을 통해 최종 소비자에게 가치를 더함.

5. **비즈니스 로직과 모델링**:
   - 데이터 변환의 주요 원인 중 하나는 비즈니스 로직.
   - 비즈니스 프로세스를 명확하고 최신화하려면 데이터 모델링이 중요.
   - 변환 전반에 걸쳐 비즈니스 로직을 표준 접근 방식으로 구현.

### 2.1.6 데이터 서빙

데이터 엔지니어링 수명 주기의 마지막 단계입니다. 이 단계에서는 데이터를 활용하여 가치를 창출합니다. 데이터로부터의 가치는 사용자마다 다르게 해석되지만, 소비되지 않는 데이터는 비활성 상태로 남게 됩니다. **데이터 레이크** 프로젝트로 인해 대규모의 데이터셋이 수집되어도, 이것이 적극적으로 활용되지 않으면 기업에 부담이 될 수 있습니다. 클라우드 시대의 데이터 프로젝트는 새로운 비즈니스 프로젝트를 위해 모던 데이터 웨어하우스, 객체 스토리지 시스템, 스트리밍 기술을 사용합니다.

**분석**  
분석은 대부분의 데이터 작업에서 핵심적인 역할을 하며, 데이터가 저장 및 변환된 후 보고서와 대시보드를 생성하고 임시 분석을 수행할 수 있습니다. 분석에는 다음과 같은 여러 종류가 있습니다:

- **비즈니스 인텔리전스**:  
  기업 경영의 과거와 현재 상태를 설명하기 위해 데이터를 수집하며, 이를 처리하는 비즈니스 로직과 정의를 유지 및 관리합니다. 비즈니스 로직은 데이터 웨어하우스를 쿼리하는 데 사용되어 보고서 및 대시보드가 기업의 정의와 일치하도록 합니다. 기업의 데이터 성숙도가 높아짐에 따라 비즈니스 사용자도 셀프 서비스 분석을 통해 직접 데이터를 분석하고 통찰력을 얻을 수 있습니다.

- **운영 분석**:  
  운영의 세부 사항을 중점으로 보고서 사용자와 함께 작업을 촉진합니다. 웹사이트나 애플리케이션 상태에 대한 실시간 대시보드를 제공하며, 원천 시스템이나 스트리밍 데이터 파이프라인에서 실시간으로 소비할 수 있습니다.

**머신러닝**  
조직이 높은 데이터 성숙도에 도달하면 머신러닝을 중심으로 문제를 파악하고 업무를 구성할 수 있습니다. 데이터 엔지니어링과 머신러닝의 경계가 모호해질 수 있지만, 다음을 지원해야 합니다:

- **스파크 클러스터**:  
  분석 파이프라인과 머신러닝 모델 훈련을 지원합니다.

- **메타데이터 및 카탈로그 시스템**:  
  데이터 기록과 계보를 추적하는 시스템을 제공하며, 팀 간 작업을 조정합니다.

- **특성 저장소**:  
  데이터 엔지니어링과 머신러닝 엔지니어링을 결합한 최신 도구로, 특성 이력과 버전을 유지하고 팀 간 특성을 공유하며 기본적인 운영과 조정 기능을 제공합니다.

데이터 엔지니어는 기본 머신러닝 기술, 데이터 처리 요구사항, 회사 내 모델의 사용 사례를 파악하고, 분석 팀과의 협업 능력을 갖춰야 합니다. 이를 통해 데이터 처리에 대해 효율적인 커뮤니케이션을 유지하고 협업을 촉진할 수 있습니다. 데이터 엔지니어는 다른 팀과 협력하여 도구를 구축할 수 있는 이상적인 인재입니다.

#### - 머신러닝 관련 데이터 서빙 단계에서 고려할 사항

1. **데이터 품질**:  
   신뢰할 수 있는 특성 엔지니어링을 수행하기에 충분한 품질의 데이터인지 확인해야 합니다. 데이터의 품질 요구 사항 및 평가는 데이터를 사용하는 팀과 긴밀하게 협력해 개발됩니다.

2. **데이터 검색 가능성**:  
   데이터 과학자와 머신러닝 엔지니어가 쉽게 접근하고 활용할 수 있도록 데이터의 검색 가능성을 확보해야 합니다.

3. **기술적 및 조직적 경계**:  
   데이터 엔지니어링과 머신러닝 엔지니어링 간의 기술적 및 조직적 경계가 명확해야 합니다. 이러한 조직 차원의 질문이 아키텍처에 큰 영향을 미칠 수 있습니다.

4. **데이터 편향 여부**:  
   데이터셋이 실제 상황을 제대로 나타내고 있는지, 특정한 편향이 존재하지는 않는지 점검해야 합니다.

머신러닝에 막대한 자원을 투자하기 전에, 신중하게 데이터를 기반으로 구축된 시스템을 만들어야 합니다. 이는 데이터 엔지니어링과 머신러닝 수명 주기 전체에 걸쳐 최적의 시스템과 인프라를 구성하는 것이 중요하다는 뜻입니다. 일반적으로 머신러닝으로 전환하기 전에 분석 역량을 충분히 개발하는 것이 가장 좋습니다.

### **2.2.1 보안**
- **최소 권한 원칙**:  
  데이터 엔지니어는 보안을 최우선으로 생각해야 하며, 데이터와 접근 보안을 모두 이해하고 최소 권한 원칙을 준수해야 합니다. 모든 사용자에게 관리자 권한을 부여하는 것은 위험한 행위이므로, 현재 업무를 수행하는 데 필요한 접근 권한만 부여해야 합니다.

- **안전한 작업 습관**:  
  표준 사용자 접근 권한을 가진 가시적인 파일을 찾을 때는 root shell을 사용하지 않으며, 낮은 테이블을 관리할 때 데이터베이스의 슈퍼 유저 권한을 사용하지 않습니다. 이러한 습관으로 최소 권한 원칙을 준수하며 사고 예방과 안전 제일의 사고방식을 유지할 수 있습니다.

- **데이터 접근 관리**:  
  사람과 시스템에 필요한 기간 동안에만 정확하게 데이터 접근을 제공해야 합니다. 암호화, 토큰화, 데이터 마스킹, 난독화 등을 활용해 저장된 데이터와 사용 중인 데이터를 모두 보호하며, 단순하고 견고한 접근 제어를 유지해야 합니다.

- **보안 지식 확장**:  
  데이터 엔지니어는 클라우드 및 온프레미스 환경에 대한 모범 사례를 이해하고, 사용자 및 아이디 접근 관리의 역할, 정책, 그룹, 네트워크 보안, 암호화 등을 다룰 수 있는 유능한 보안 관리자여야 합니다. 보안 관련 지식을 쌓기 위한 좋은 출발점으로 고려해보세요.

### 2.2.2 데이터 관리

- **DMBoK 정의**:  
  데이터 관리 지식 책 DMBoK에 따르면, 데이터 관리는 수명 주기 전체에 걸쳐 데이터와 정보 자산의 가치를 제공, 제어, 보호, 향상하기 위한 계획, 정책, 프로그램, 사례를 개발, 실행 및 감독하는 것입니다.

- **데이터 관리의 중요성**:  
  데이터 엔지니어는 수명 주기 전반에 걸쳐 데이터를 관리하고, 데이터 관리에는 다음과 같은 측면들이 포함됩니다:

  - **데이터 거버넌스**:  
    발견 가능성과 책임을 다루는 데이터 거버넌스.

  - **데이터 모델링 및 설계**:  
    효율적인 데이터 모델링과 설계.

  - **데이터 계보**:  
    데이터 계보 추적.

  - **저장 및 운영**:  
    데이터 저장과 운영 관리.

  - **데이터 통합 및 상호 운용성**:  
    다양한 시스템 간 데이터 통합과 상호 운용성.

  - **데이터 수명 주기 관리**:  
    수명 주기 전반에 걸친 데이터 관리.

  - **고급 분석 및 머신 러닝**:  
    고급 분석 및 머신러닝을 위한 데이터 시스템.

  - **윤리 및 개인 정보 보호**:  
    데이터의 윤리적 사용과 개인 정보 보호.

#### 데이터 거버넌스
- **정의**:  
  데이터 거버넌스는 조직이 수집한 데이터의 품질, 무결성, 보안, 사용성을 보장하는 기능입니다. 이를 통해 조직 전체의 데이터 가치를 극대화하면서 적절한 보안 제어로 데이터를 보호할 수 있습니다.

- **중요성**:  
  우발적이거나 무계획적인 데이터 거버넌스는 보안 침해 등 다양한 부작용을 초래할 수 있습니다. 그러나 의도적인 접근을 통해 조직의 데이터 역량과 데이터 가치를 극대화할 수 있습니다.

- **핵심 범주**:  
  데이터 거버넌스의 핵심 범주는 다음과 같습니다:
  - **발견 가능성**:  
    데이터를 쉽게 검색하고 사용할 수 있어야 합니다. 사용자는 필요한 데이터에 신속하고 안정적으로 접근하며 데이터의 출처, 관계, 의미를 이해해야 합니다.

  - **보안**:  
    데이터를 보호하기 위한 적절한 보안 정책을 유지해야 합니다.

  - **책임**:  
    데이터 사용과 관련된 책임을 명확히 해야 합니다.

##### 메타데이터
- **정의**:  
  메타데이터는 데이터에 대한 데이터로, 데이터를 검색하고 제어하는 데 필수적입니다.

- **분류**:  
  메타데이터는 크게 자동 생성 데이터와 인간 생성 데이터로 나뉩니다. 자동화가 일반적이지만, 수작업으로 수집된 메타데이터는 오류가 발생하기 쉽습니다.

- **도구**:  
  데이터 카탈로그, 데이터 계보 추적 시스템, 메타데이터 관리 도구 등을 통해 데이터베이스를 탐색하고 관계를 파악하며, 데이터 파이프라인을 모니터링해 데이터의 출처와 타깃을 추적할 수 있습니다.

- **사회적 요소**:  
  메타데이터에는 사회적 요소가 포함됩니다. 조직은 프로세스, 데이터셋, 파이프라인에 대한 지식을 축적하며, 메타데이터 시스템은 이러한 사회적 측면에 초점을 맞춰야 합니다.

- **활용**:  
  메타데이터 시스템과 프로세스를 통해 데이터 엔지니어는 메타데이터를 수명 주기 전체에 걸쳐 파이프라인 설계와 데이터 관리에 활용할 수 있습니다.

##### DMBOK에서 식별한 메타데이터의 네 가지 주요 범주

1. **비즈니스 메타데이터**  
   - **내용**: 비즈니스 및 데이터 정의, 데이터 규칙과 로직, 데이터 사용 방법과 장소, 데이터 소유자 등과 관련된 정보를 포함.
   - **용도**: 데이터 엔지니어가 데이터 사용의 콘텍스트와 정의를 파악하여 적절하게 활용할 수 있도록 도움.

2. **기술 메타데이터**  
   - **내용**: 데이터 모델과 스키마, 데이터 계보, 필드 맵핑, 파이프라인 워크플로우 등의 정보를 담고 있음.
   - **용도**: 데이터 엔지니어가 시스템을 생성하고 연결하며, 전체 수명 주기를 모니터링하는 데 사용.
   - **일반 유형**
     - **파이프라인 메타데이터**: 워크플로우 일정, 데이터 종속성, 구성 세부 정보 등.
     - **데이터 계보 메타데이터**: 데이터 원본 및 변형 기록을 추적하고 데이터 간 관계를 나타냄.
     - **스키마 메타데이터**: 데이터 구조를 설명하며 시스템에 저장된 데이터를 나타냄.

3. **운영 메타데이터**  
   - **내용**: 시스템의 운영 결과와 관련된 정보로, 프로세스 작업, 애플리케이션 런타임 로그, 오류 로그 등을 포함.
   - **용도**: 데이터 엔지니어가 프로세스 성공 또는 실패 여부를 판단하고, 관련된 데이터를 식별할 수 있도록 도움.
   - **특징**: 오케스트레이션 시스템에서는 제한된 정보를 제공하지만, 운영 메타데이터는 분산 경향이 있음.

4. **참조 메타데이터**  
   - **내용**: 다른 데이터를 분류하는 데 필요한 데이터로 조회 데이터로도 불림. 내부 코드, 지리적 코드, 특정 단위, 내부 달력 표준 등이 이에 포함.
   - **특징**: 대부분의 참조 데이터는 내부적으로 관리되지만, 외부 표준을 사용할 수도 있음. 시간이 지나도 서서히 변경되는 경향이 있음.

##### 데이터 책임
- **의미**: 데이터의 일부를 관리할 개인을 지정하는 것. 이 책임자는 다른 이해 관계자의 거버넌스 활동을 조정하며, 데이터 책임은 다양한 수준에서 발생할 수 있음.
  - 예: 테이블 또는 로그 스트림 수준, 단일 필드 엔티티 등.

- **데이터 품질**
  - 데이터가 비즈니스 메타데이터의 기대치에 부합하는지 검토하는 것이 핵심.
  - 데이터 품질 테스트를 통해 스키마 기대치, 데이터 완전성, 정밀도 등에 대한 준수를 보장.

- **주요 특징**
  - **정확도**: 수집된 데이터가 정확한지, 중복된 값이 없는지, 수치가 정확한지 확인.
  - **완전성**: 모든 필수 필드에 유효한 값이 포함되어 있는지 확인.
  - **적시성**: 데이터를 적시에 이용할 수 있는지 확인.

##### 마스터 데이터 관리(MDM)
- **마스터 데이터**: 직원, 고객, 제품, 위치 등 비즈니스 엔티티에 관한 데이터.
- **마스터 데이터 관리**:
  - **골든 레코드**: 조직 및 파트너 간에 일관된 엔티티 정의를 구축하는 관행.
  - **역할**: 조직 내 엔티티 데이터를 조화시키는 작업.
  - **프로세스**: 기술 도구를 구축하고 배포하여 표준 엔티티 데이터를 확보.
  - 예: MDM 팀이 주소의 표준 형식을 정한 후 데이터 엔지니어와 함께 API를 구축하여 회사 부서 전반에 일관된 고객 레코드를 제공.

#### 데이터 모델링 및 설계
- **의의**: 비즈니스 분석 및 데이터 과학을 통해 데이터에서 인사이트를 얻으려면, 데이터는 사용 가능한 형태로 제공되어야 함.
  - 이를 위해 데이터를 변환하는 과정을 **데이터 모델링 및 설계**라고 함.

- **역할의 확장**: 데이터베이스 관리자와 ETL 개발자만의 역할이 아니며, 조직 전반에서 이루어질 수 있음.
  - 다양한 데이터 원천과 사용 사례로 인해 모델링이 더욱 어려워지고 있음.

- **도전과제**:
  - 엄격한 정규화 방식이 모든 데이터 유형에 적용되지 않음.
  - 클라우드 데이터 웨어하우스는 비정형 데이터도 처리할 수 있어야 함.
  - 데이터 처리 프레임워크는 플랫 정형 관계형 레코드에서 원시 비정형 텍스트에 이르는 다양한 데이터를 수집해야 함.

- **유연성 개발**:
  - 데이터 엔지니어는 다양한 데이터 원천과 사용 사례에 적합한 수준과 유형의 모델링을 적용해야 함.
  - 데이터 모델링 모범 사례를 이해하고, 데이터의 종류에 맞춰 효율적인 모델링을 적용할 수 있어야 함.


#### 데이터 모델링 및 설계
- **목적**: 비즈니스 분석과 데이터 과학을 통해 데이터에서 인사이트를 얻으려면, 데이터를 사용 가능한 형태로 제공해야 합니다. 이를 위해 데이터를 구조화하는 과정을 **데이터 모델링 및 설계**라고 합니다.

- **역할의 범위**: 전통적으로 데이터베이스 관리자와 ETL 개발자의 책임으로 간주되었지만, 데이터 모델링은 조직 전반에서 이루어져야 합니다.

- **과제**:
  - **새로운 데이터 원천과 사용 사례**로 인해 데이터 모델링이 복잡해지고 있습니다.
  - 엄격한 정규화 방식은 모든 데이터에 적합하지 않습니다.
  - 클라우드 데이터 웨어하우스는 방대한 양의 비정형 및 반정형 데이터를 수집, 처리합니다.
  - 스파크와 같은 데이터 처리 프레임워크는 단순한 정형 데이터부터 복잡한 비정형 데이터까지 처리합니다

- **유연성 개발**:
  - 데이터 엔지니어는 데이터 원천과 사용 사례에 적합한 모델링 방식을 선택해야 합니다.
  - 데이터 모델링의 모범 사례를 이해하고, 각 데이터 유형에 따라 적절한 수준과 형태의 모델링을 적용할 수 있어야 합니다.

#### 데이터 계보
- **정의**: 데이터 계보는 데이터를 처리한 시스템과 데이터가 의존하는 업스트림 데이터를 추적하여, 수명 주기 전체에서 데이터의 감사 추적을 기록하는 것을 말합니다.

- **목적 및 이점**:
  - 데이터가 이동하고 변환되는 과정에서 어떤 시스템이 영향을 미쳤는지 파악합니다.
  - 데이터에 포함된 구성 요소와 그 출처를 추적합니다.
  - 데이터 및 시스템의 오류를 추적하고 설명하며 디버깅에 도움을 줍니다.
  - 수명 주기 전반에 걸친 감사 추적을 제공해 규정 준수에도 도움이 됩니다.


#### 데이터 통합과 상호 운용성

- **정의**: 여러 도구와 프로세스 전반에 걸쳐 데이터를 통합하는 프로세스.

- **배경**:
  - 과거 단일 스택 접근 방식에서 다양한 도구가 데이터를 온디맨드로 처리하는 이기종 클라우드 환경으로 전환.
  - 이 변화는 데이터 엔지니어의 작업 범위를 확장.

- **특징**:
  - 데이터 통합이 맞춤형 데이터베이스 연결 대신 범용 API를 통해 이루어짐.
  - 데이터 처리보다는 파이썬 코드를 통한 데이터 시스템과의 간단한 통신.
  - 상호작용의 복잡성 감소 대신 시스템 수와 데이터 파이프라인의 복잡성 증가.

#### 데이터 수명 주기 관리
- **문제 인식**: 데이터 레이크의 등장으로 조직이 데이터 보관 및 폐기를 무시하기 시작했음. 그러나 데이터 엔지니어링 수명 주기의 마지막 단계에 더 많은 관심을 기울이게 하는 두 가지 변화가 있음.

- **두 가지 변화**:
  - **클라우드 스토리지 비용**: 클라우드 스토리지 사용 증가로 초기 자본 지출 대신 종량제 스토리지 비용 발생. 주요 클라우드 벤더는 저렴한 비용의 장기간 보존용 아카이브 스토리지 클래스를 제공함.
  - **데이터 보존법**: GDPR과 CCPA 같은 법률로 인해 데이터 엔지니어는 사용자의 '잊혀질 권리'를 존중하기 위해 데이터 파기를 관리해야 함.

- **조치 및 도구**:
  - 데이터 엔지니어는 현재 보유한 소비자 데이터를 파악하고, 요청 및 컴플라이언스 요건에 따라 데이터 파기 절차를 수행해야 함.
  - 클라우드 데이터 웨어하우스에서 **SQL**의 `WHERE` 절로 쉽게 데이터 삭제 가능.
  - **하이브 ACID** 및 **델타 레이크** 같은 도구를 사용해 규모에 맞는 데이터 삭제 트랜잭션을 쉽게 관리함.
  - 차세대 메타데이터 관리, 데이터 계보, 카탈로그 도구로 수명 주기의 마지막 단계를 간소화할 수 있음.

### 2.2.3 데이터옵스

**데이터옵스**는 애자일 방법론, 데브옵스, 통계적 공정 관리(SPC)의 모범 사례를 데이터 관리에 적용하는 방식임. 데브옵스가 소프트웨어 릴리즈와 품질을 개선하는 것처럼, 데이터옵스는 데이터 제품에 대해 같은 작업을 수행함.

**목표**:
- 신속한 혁신과 실험으로 고객에게 새로운 통찰력 제공
- 높은 데이터 품질과 낮은 오류율 달성
- 복잡한 인력, 기술, 환경 간 협업 촉진
- 명확한 측정, 모니터링 및 투명성 확보

**핵심 요소**:
- **자동화**: 반복적이고 수동적인 작업을 최소화해 효율을 높임.
- **모니터링 및 관찰 가능성**: 시스템 성능을 파악해 문제를 조기에 발견하고 대응함.
- **사고 대응**: 발생한 문제에 빠르게 대응할 수 있는 절차 마련.

**문화적 중요성**:
- 데이터옵스는 단순한 기술이 아니라 **문화적 습관**임.
- 데이터 엔지니어링 팀은 **협업, 지속적 학습, 빠른 반복 주기** 등의 문화적 습관을 정착시켜야 함.
- 이 습관이 있어야만 도구와 기술을 통해 최상의 결과를 얻을 수 있음.

**도입 전략**:
- 데이터 인프라가 없는 기업이라면 처음부터 데이터옵스를 도입할 수 있는 기회가 됨.
- 기존 시스템을 가진 기업은 모니터링 및 관찰 가능성부터 시작해 시스템 성능을 파악하고, 이후 자동화와 사고 대응 기능을 추가함.
- 기존 데이터옵스 팀과 협력해 기업의 데이터 성숙도에 맞춰 데이터 엔지니어링 수명 주기를 계산할 수 있음.


#### 자동화

**목적**: 데이터옵스에서 자동화를 통해 프로세스의 **신뢰성과 일관성**을 보장함. 이를 통해 데이터 엔지니어는 새로운 기능이나 계산을 빠르게 기존 워크플로에 구현할 수 있음.

**데브옵스와의 유사성**:
- 자동화는 데브옵스의 변경 관리, 지속적 통합 및 배포 등과 유사한 프레임워크 및 워크플로를 가짐.
- 데이터옵스 자동화는 데이터 품질, 데이터 모델 변화, 메타데이터 무결성 등을 확인해 기술과 시스템의 신뢰성을 유지함.

**원칙**:
- 데이터옵스의 원칙 중 하나인 **변화 수용**은 목표 지향적 변화임.
- 자동화 단계마다 운영 개선의 기회가 있음.

**고도화 가능성**:
- 메타데이터 역량을 기반으로 한 차세대 조정 프레임워크 도입
- 데이터 계보를 기반으로 DAG를 자동으로 구축하는 프레임워크 개발

**핵심**: 엔지니어는 자동화를 통해 워크로드를 줄이고, 비즈니스에 제공하는 가치를 높이는 방향으로 지속적인 개선을 추구해야 함.

#### 관찰 가능성과 모니터링

- **필요성**: 불량 데이터의 사례는 수없이 많음. 잘못된 데이터로 인한 결정 오류는 시간이 지나서야 발견되며, 이는 때로는 비즈니스에 치명적임. 데이터와 데이터 생성 시스템을 감시하지 않으면 데이터 문제에 직면할 수 있음.

- **중요성**: 관찰 가능성, 모니터링, 로깅, 경고, 추적은 데이터 엔지니어링 수명 주기에서 발생하는 문제에 대처하는 데 필수적임. SPC(통계적 공정 관리)를 통합해 이벤트의 문제 여부와 대응 필요성을 파악하는 것이 좋음.

- **DODD 방법론**:
  - 페트렐라의 DODD(Data Observability-Driven Development) 방법론은 소프트웨어의 TDD(Test-Driven Development)와 유사함.
  - DODD의 목적은 데이터와 데이터 애플리케이션에 대한 가시성을 확보하고 변경 사항을 수집해 모든 단계에서 문제를 식별함으로써, 데이터 문제를 해결하거나 예방하는 데 있음.
  - 데이터 엔지니어링 수명 주기에서 **관찰 가능성**을 최우선 고려 사항으로 삼음.


